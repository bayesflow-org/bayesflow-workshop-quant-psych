[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Seminar in Amortized Bayesian Inference",
    "section": "",
    "text": "A relatively persistent phenomenon observed in decision-making tasks is the occurrence of double responses, where participants, after making an initial response, rapidly make a second response for an alternative option. For example, in a classic lexical decision task, participants are asked to judge whether a presented string of letters is a word or a non-word. A double response might occur if a participant first presses a key corresponding to word but immediately follows up with another key press corresponding to non-word. In most experiments, double responses are not of primary interest and are typically excluded or not recorded at all.\nHowever, Evans et al. (2020) argued that double responses might provide additional information about the underlying decision process. They proposed modifications to a selection of evidence accumulation models (EAMs) to account for this phenomenon. For most of the models examined by Evans et al. (2020), the analytic likelihood is unknown, requiring the authors to use extensive simulation-based estimation, where the likelihood is approximated via a kernel density estimate on simulated data.\nIn this project, you could select a specific model of double responses proposed by Evans et al. (2020) and implement it in BayesFlow. Following this, you may reproduce the analysis using data from Dutilh et al. (2009). Alternatively, you can implement two versions of one model - one which accounts for double responses and one which does not. Investigate under which circumstances including information about double responding brings valuable information about the model parameters (e.g., by investigating whether including double responses increases posterior contraction).\nDownload data from Dutilh et al. (2009), reported by Evans et al. (2020) at in the OSF repository:\n\nparticipant_1.csv\nparticipant_2.csv\nparticipant_3.csv\nparticipant_4.csv"
  },
  {
    "objectID": "projects.html#double-responding",
    "href": "projects.html#double-responding",
    "title": "Seminar in Amortized Bayesian Inference",
    "section": "",
    "text": "A relatively persistent phenomenon observed in decision-making tasks is the occurrence of double responses, where participants, after making an initial response, rapidly make a second response for an alternative option. For example, in a classic lexical decision task, participants are asked to judge whether a presented string of letters is a word or a non-word. A double response might occur if a participant first presses a key corresponding to word but immediately follows up with another key press corresponding to non-word. In most experiments, double responses are not of primary interest and are typically excluded or not recorded at all.\nHowever, Evans et al. (2020) argued that double responses might provide additional information about the underlying decision process. They proposed modifications to a selection of evidence accumulation models (EAMs) to account for this phenomenon. For most of the models examined by Evans et al. (2020), the analytic likelihood is unknown, requiring the authors to use extensive simulation-based estimation, where the likelihood is approximated via a kernel density estimate on simulated data.\nIn this project, you could select a specific model of double responses proposed by Evans et al. (2020) and implement it in BayesFlow. Following this, you may reproduce the analysis using data from Dutilh et al. (2009). Alternatively, you can implement two versions of one model - one which accounts for double responses and one which does not. Investigate under which circumstances including information about double responding brings valuable information about the model parameters (e.g., by investigating whether including double responses increases posterior contraction).\nDownload data from Dutilh et al. (2009), reported by Evans et al. (2020) at in the OSF repository:\n\nparticipant_1.csv\nparticipant_2.csv\nparticipant_3.csv\nparticipant_4.csv"
  },
  {
    "objectID": "projects.html#swift-model",
    "href": "projects.html#swift-model",
    "title": "Seminar in Amortized Bayesian Inference",
    "section": "SWIFT model",
    "text": "SWIFT model\nCognitive models are widely used in decision-making research, where participants respond to stimuli by making choices. However, their applications extend far beyond this domain (Rasanan et al., 2024).\nOne area where cognitive models have advanced our understanding is visual processing. These models predict how gaze direction is driven by the cognitive state of the observer, but also their environment. However, eye movement behavior is complex, and many models produce intractable likelihoods, making amortized inference a promising approach.\nA notable example is SWIFT, a dynamic model of eye movement control during reading. The original version (Engbert et al., 2005) is challenging to fit, but a simplified variant (Engbert & Rabe, 2024) allows for more efficient likelihood calculation, making SWIFT an excellent starting point for implementing models of eye movement behavior with BayesFlow.\nIn this project, you can explore amortized inference for the SWIFT model using the simplified version from Engbert & Rabe (2024). The OSF repository of the tutorial paper provides relevant datasets, including individual participant data and a language corpus. For instance, you can download data from one participant from https://osf.io/teyd4 and load it into Python:\nimport pandas as pd\n\ndf=pd.read_csv(\"fixseqin_PB2expVP10.dat\", \n    delimiter=\"\\t\", \n    names=[\"sentID\", \"wordID\", \"duration\"], \n    usecols=[0, 1, 3])\nwhere sentID and wordID columns indicate the sentence id and word id that was fixated, and duration column represents fixation duration (in ms).\nTo obtain word frequencies, download the corpus data from https://osf.io/nj2mf and load it into Python:\nimport pandas as pd\n\ncorpus=pd.read_csv(\"Rcorpus_PB2.dat\", delimiter=\"\\t\", usecols=range(5))\nThe relevant columns are sentID and wordID that allow you to match the fixated word to a word from the corpus, and freq which gives the word frequency.\n\nReferences\n\n\nDutilh, G., Vandekerckhove, J., Tuerlinckx, F., & Wagenmakers, E.-J. (2009). A diffusion model decomposition of the practice effect. Psychonomic Bulletin & Review, 16, 1026–1036.\n\n\nEngbert, R., Nuthmann, A., Richter, E. M., & Kliegl, R. (2005). SWIFT: A dynamical model of saccade generation during reading. Psychological Review, 112(4), 777.\n\n\nEngbert, R., & Rabe, M. M. (2024). A tutorial on bayesian inference for dynamical modeling of eye-movement control during reading. Journal of Mathematical Psychology, 119, 102843.\n\n\nEvans, N. J., Dutilh, G., Wagenmakers, E.-J., & van der Maas, H. L. (2020). Double responding: A new constraint for models of speeded decision making. Cognitive Psychology, 121, 101292.\n\n\nRasanan, A. H. H., Evans, N. J., Fontanesi, L., Manning, C., Huang-Pollock, C., Matzke, D., Heathcote, A., Rieskamp, J., Speekenbrink, M., Frank, M. J., et al. (2024). Beyond discrete-choice options. Trends in Cognitive Sciences."
  },
  {
    "objectID": "exercises/bayesflow-normal.html",
    "href": "exercises/bayesflow-normal.html",
    "title": "Simulator",
    "section": "",
    "text": "import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras\nimport bayesflow as bf\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef context(batch_size, n=None):\n    if n is None:\n        n = np.random.randint(10, 101)\n\n    return dict(n=n)\n\ndef prior(mu=None, sigma=None):\n    if mu is None:\n        mu = np.random.normal()\n    if sigma is None:\n        sigma = np.random.gamma(shape=2)\n\n    return dict(mu=mu, sigma=sigma)\n\ndef likelihood(n, mu, sigma):\n    y = np.random.normal(mu, sigma, size=n)\n\n    return dict(y=y)\n\ndef summary(y):\n    mean = np.mean(y)\n    sd = np.std(y, ddof=1)\n    \n    return dict(mean=mean, sd=sd)\nsimulator = bf.make_simulator([prior, likelihood, summary], meta_fn=context)"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#approximator",
    "href": "exercises/bayesflow-normal.html#approximator",
    "title": "Simulator",
    "section": "Approximator",
    "text": "Approximator\n\nadapter = (bf.Adapter()\n    .broadcast(\"n\", to=\"mean\")\n    .constrain(\"sigma\", lower=0)\n    .concatenate([\"n\", \"mean\", \"sd\"], into=\"inference_conditions\")\n    .concatenate([\"mu\", \"sigma\"], into=\"inference_variables\")\n    .drop(\"y\")\n    )\n\n\nadapter(data)\n\n{'inference_conditions': array([[74.        ,  0.76694314,  1.39422227],\n        [74.        , -0.6229432 ,  3.08988216],\n        [74.        ,  0.44475618,  2.75734839],\n        ...,\n        [74.        ,  0.17871722,  1.68871381],\n        [74.        ,  0.42637994,  1.1742368 ],\n        [74.        , -0.22511094,  1.84774964]]),\n 'inference_variables': array([[ 0.84486274,  1.37260244],\n        [-0.34209391,  3.25960583],\n        [ 0.22161927,  2.77719178],\n        ...,\n        [-0.25682988,  1.46655423],\n        [ 0.48404955,  0.72521255],\n        [-0.21675392,  1.62647277]])}\n\n\n\napproximator = bf.approximators.ContinuousApproximator(\n    inference_network=bf.networks.CouplingFlow(permutation=\"swap\", subnet_kwargs=dict(dropout=False)),\n    adapter=adapter\n)\n\n\nepochs=10\nnum_batches=100\nbatch_size=256\n\n\nschedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=1e-3, decay_steps=epochs * num_batches)\noptimizer = keras.optimizers.Adam(learning_rate=schedule)\n\n\napproximator.compile(optimizer)\n\n\nhistory=approximator.fit(\n    epochs=epochs,\n    num_batches=num_batches,\n    batch_size=batch_size,\n    simulator=simulator)\n\nINFO:bayesflow:Building dataset from simulator instance of SequentialSimulator.\nINFO:bayesflow:Using 10 data loading workers.\nINFO:bayesflow:Building on a test batch.\n\n\nEpoch 1/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 8s 14ms/step - loss: 3.4837 - loss/inference_loss: 3.4837\nEpoch 2/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - loss: 2.0692 - loss/inference_loss: 2.0692\nEpoch 3/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 17ms/step - loss: 1.5248 - loss/inference_loss: 1.5248\nEpoch 4/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 17ms/step - loss: 1.6958 - loss/inference_loss: 1.6958\nEpoch 5/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - loss: 0.8813 - loss/inference_loss: 0.8813\nEpoch 6/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - loss: 0.4748 - loss/inference_loss: 0.4748\nEpoch 7/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - loss: 0.4894 - loss/inference_loss: 0.4894\nEpoch 8/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - loss: 0.0512 - loss/inference_loss: 0.0512\nEpoch 9/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 17ms/step - loss: 0.1660 - loss/inference_loss: 0.1660\nEpoch 10/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - loss: 0.0928 - loss/inference_loss: 0.0928\n\n\n\nfig=bf.diagnostics.plots.loss(history)"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#validation",
    "href": "exercises/bayesflow-normal.html#validation",
    "title": "Simulator",
    "section": "Validation",
    "text": "Validation\n\ntest_data = simulator.sample(1000, n=50)\nprior = dict(mu=test_data[\"mu\"], sigma=test_data[\"sigma\"])\nposterior = approximator.sample(num_samples=500, conditions=test_data)\n\n\nfig=bf.diagnostics.plots.calibration_ecdf(estimates=posterior, targets=prior)\n\n\n\n\n\n\n\n\n\nfig=bf.diagnostics.z_score_contraction(estimates=posterior, targets=prior)\n\n\n\n\n\n\n\n\n\nfig=bf.diagnostics.plots.recovery(estimates=posterior, targets=prior)"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#inference",
    "href": "exercises/bayesflow-normal.html#inference",
    "title": "Simulator",
    "section": "Inference",
    "text": "Inference\n\ninference_data = dict(n=50, mean=np.array([[0.5]]), sd=np.array([[2]]))\n\n\nposterior = approximator.sample(num_samples=1000, conditions=inference_data)\n\n\nfig=bf.diagnostics.pairs_posterior(estimates=posterior, priors=prior)"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#approximator-1",
    "href": "exercises/bayesflow-normal.html#approximator-1",
    "title": "Simulator",
    "section": "Approximator",
    "text": "Approximator\n\nadapter = (bf.Adapter()\n    .broadcast(\"n\", to=\"y\")\n    .as_set(\"y\")\n    .constrain(\"sigma\", lower=0)\n    .rename(\"n\", \"inference_conditions\")\n    .rename(\"y\", \"summary_variables\")\n    .concatenate([\"mu\", \"sigma\"], into=\"inference_variables\")\n    .drop([\"mean\", \"sd\"])\n    )\n\n\nworkflow = bf.BasicWorkflow(\n    inference_network=bf.networks.CouplingFlow(subnet_kwargs=dict(dropout=False)), \n    summary_network=bf.networks.DeepSet(\n        base_distribution=\"normal\",\n        dropout=False,\n        mlp_widths_equivariant=(16, 16), \n        mlp_widths_invariant_inner=(16, 16),\n        mlp_widths_invariant_outer=(16, 16),\n        mlp_widths_invariant_last=(16, 16)\n        ),\n    simulator=simulator,\n    adapter=adapter,\n    inference_variables=[\"mu\", \"sigma\"],\n    inference_conditions=\"n\",\n    summary_variables=\"y\"\n)\n\n\nhistory=workflow.fit_online(epochs=epochs, num_batches_per_epoch=num_batches, batch_size=batch_size)\n\nINFO:bayesflow:Fitting on dataset instance of OnlineDataset.\nINFO:bayesflow:Building on a test batch.\n\n\nEpoch 1/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 13s 36ms/step - loss: 3.2360 - loss/inference_loss: 2.8069 - loss/summary_loss: 0.4291\nEpoch 2/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 54ms/step - loss: 1.7409 - loss/inference_loss: 1.4738 - loss/summary_loss: 0.2671\nEpoch 3/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 54ms/step - loss: 1.1521 - loss/inference_loss: 0.9118 - loss/summary_loss: 0.2404\nEpoch 4/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 59ms/step - loss: 0.7384 - loss/inference_loss: 0.5291 - loss/summary_loss: 0.2093\nEpoch 5/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 64ms/step - loss: 0.5829 - loss/inference_loss: 0.3884 - loss/summary_loss: 0.1945\nEpoch 6/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 59ms/step - loss: 0.4831 - loss/inference_loss: 0.2973 - loss/summary_loss: 0.1858\nEpoch 7/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 59ms/step - loss: 0.4428 - loss/inference_loss: 0.2589 - loss/summary_loss: 0.1839\nEpoch 8/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 57ms/step - loss: 0.2853 - loss/inference_loss: 0.1048 - loss/summary_loss: 0.1806\nEpoch 9/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 56ms/step - loss: 0.3235 - loss/inference_loss: 0.1441 - loss/summary_loss: 0.1793\nEpoch 10/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 61ms/step - loss: 0.3194 - loss/inference_loss: 0.1401 - loss/summary_loss: 0.1793"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#validation-1",
    "href": "exercises/bayesflow-normal.html#validation-1",
    "title": "Simulator",
    "section": "Validation",
    "text": "Validation\n\ntest_data = simulator.sample(1000, n=50)\n\n\nplots=workflow.plot_default_diagnostics(test_data=test_data)"
  },
  {
    "objectID": "exercises/bayesflow-normal.html#inference-1",
    "href": "exercises/bayesflow-normal.html#inference-1",
    "title": "Simulator",
    "section": "Inference",
    "text": "Inference\n\ninference_data = dict(\n    y = np.random.normal(loc=1, scale=0.6, size=(1, 50)),\n    n = 50)\n\n\nnum_samples=2_000\n\n\nposterior=workflow.sample(num_samples=num_samples, conditions=inference_data)\nposterior=keras.tree.map_structure(np.squeeze, posterior)\n\n\nfig=bf.diagnostics.pairs_posterior(posterior)\n\n\n\n\n\n\n\n\n\nposterior_predictives = simulator.sample(num_samples, n=50, **posterior)\n\n\nsummary(inference_data[\"y\"])\n\n{'mean': 1.088498213383434, 'sd': 0.5756757855259478}\n\n\n\nfig=bf.diagnostics.pairs_samples(posterior_predictives, variable_keys=[\"mean\", \"sd\"])\n\n\n\n\n\n\n\n\n\nfig=plt.violinplot(posterior_predictives[\"y\"], showmeans=True, side=\"low\")\nfig=plt.scatter(x=[i+1 for i in range(inference_data[\"n\"])], y=inference_data[\"y\"], c=\"black\", zorder=100)\n\n\n\n\n\n\n\n\n\nsummaries_null=workflow.summary_network(workflow.simulate_adapted(1000)['summary_variables'])\nsummaries_ref=workflow.summary_network(workflow.simulate_adapted(500)['summary_variables'], training=False)\n\n\nmmd_null = [\n    bf.metrics.functional.maximum_mean_discrepancy(summaries_null, summaries_ref[i:i+1]).numpy() for i in range(500)\n]\n\n\nsummaries_obs=workflow.summary_network(adapter(inference_data, strict=False)[\"summary_variables\"])\nmmd_obs=bf.metrics.functional.maximum_mean_discrepancy(summaries_null, summaries_obs)\n\n\nfig=bf.diagnostics.plots.mmd_hypothesis_test(mmd_null, mmd_obs)"
  },
  {
    "objectID": "exercises/bayesflow-diffusion.html",
    "href": "exercises/bayesflow-diffusion.html",
    "title": "Simple response time (Wald model)",
    "section": "",
    "text": "import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras\nimport bayesflow as bf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef evidence_accumulation(nu, max_t, dt):\n    timesteps = int(max_t / dt)\n    t = np.linspace(0, max_t, timesteps)\n\n    noise = np.random.normal(0, 1, size=timesteps) * np.sqrt(dt)\n    evidence = nu * t + np.cumsum(noise)\n\n    return t, evidence\n\nt, evidence = evidence_accumulation(nu=2.5, max_t=1.0, dt=0.01)\n\nplt.plot(t, evidence)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Evidence\")\n\nText(0, 0.5, 'Evidence')\nHere we will train a simple response time model based on a single accumulator that diffuses with a drift \\(\\nu\\) to a decision threshold \\(\\alpha\\). For more background about the Wald model, see Anders, Alario, & van Maanen (2016). Here we will estimate only the drift and decision threshold, no non-decision time or variability in starting point. In this case, the mean and a standard deviation of the response times are sufficient statistics, so we do not need a summary network.\ndef prior():\n    # drift rate\n    nu=np.random.gamma(shape=10, scale=0.25)\n    # decision threshold\n    alpha=np.random.gamma(shape=10, scale=0.1)\n\n    return dict(nu=nu, alpha=alpha)\n\n# generate data for a single trial\ndef trial(nu, alpha, max_t, dt):\n    t, evidence = evidence_accumulation(nu, max_t, dt)\n    passage = np.argmax(evidence &gt; alpha)\n    rt = max_t if passage==0 else t[passage]\n\n    return rt\n\n# generate data for n trials\ndef likelihood(nu, alpha, n=250, max_t=3.0, dt=0.02):\n    rt = np.zeros(n)\n    for i in range(n):\n        rt[i] = trial(nu, alpha, max_t, dt)\n\n    return dict(rt=rt)\n\n# sufficient statistics: mean, sd, n\ndef summary(rt):\n    return dict(\n        mean = np.mean(rt),\n        sd = np.std(rt)\n    )\n\nsimulator = bf.make_simulator([prior, likelihood, summary])\ndf = simulator.sample(1_000)\nf=bf.diagnostics.pairs_samples(\n    df, \n    variable_keys=[\"nu\", \"alpha\", \"mean\", \"sd\"],\n    variable_names=[r\"$\\nu$\", r\"$\\alpha$\", \"mean RT\", \"sd RT\"])\nadapter = (bf.Adapter()\n    .constrain([\"nu\", \"alpha\"], lower=0)\n    .concatenate([\"nu\", \"alpha\"], into=\"inference_variables\")\n    .concatenate([\"mean\", \"sd\"], into=\"inference_conditions\")\n    .drop(\"rt\")\n)\nworkflow = bf.BasicWorkflow(\n    simulator = simulator,\n    adapter = adapter,\n    inference_network = bf.networks.CouplingFlow(permutation=\"swap\", subnet_kwargs=dict(dropout=False)),\n    inference_variables = [\"nu\", \"alpha\"],\n    inference_conditions = [\"mean\", \"sd\"]\n)\ntrain_data = simulator.sample(5_000)\nvalidation_data = simulator.sample(1_000)\nhistory=workflow.fit_offline(\n    data=train_data, \n    epochs=50, \n    batch_size=250, \n    validation_data=validation_data\n)\n\nINFO:bayesflow:Fitting on dataset instance of OfflineDataset.\nINFO:bayesflow:Building on a test batch.\n\n\nEpoch 1/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 6s 29ms/step - loss: 4.2478 - loss/inference_loss: 4.2478 - val_loss: 3.2971 - val_loss/inference_loss: 3.2971\nEpoch 2/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - loss: 2.9337 - loss/inference_loss: 2.9337 - val_loss: 2.6266 - val_loss/inference_loss: 2.6266\nEpoch 3/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 2.5289 - loss/inference_loss: 2.5289 - val_loss: 2.4140 - val_loss/inference_loss: 2.4140\nEpoch 4/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 2.3225 - loss/inference_loss: 2.3225 - val_loss: 2.1312 - val_loss/inference_loss: 2.1312\nEpoch 5/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - loss: 2.1697 - loss/inference_loss: 2.1697 - val_loss: 1.9862 - val_loss/inference_loss: 1.9862\nEpoch 6/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: 1.9923 - loss/inference_loss: 1.9923 - val_loss: 1.9073 - val_loss/inference_loss: 1.9073\nEpoch 7/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: 1.7246 - loss/inference_loss: 1.7246 - val_loss: 1.4878 - val_loss/inference_loss: 1.4878\nEpoch 8/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: 1.2075 - loss/inference_loss: 1.2075 - val_loss: 0.6958 - val_loss/inference_loss: 0.6958\nEpoch 9/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: 0.4581 - loss/inference_loss: 0.4581 - val_loss: -0.1159 - val_loss/inference_loss: -0.1159\nEpoch 10/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -0.3128 - loss/inference_loss: -0.3128 - val_loss: -0.5834 - val_loss/inference_loss: -0.5834\nEpoch 11/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -0.7989 - loss/inference_loss: -0.7989 - val_loss: -1.0047 - val_loss/inference_loss: -1.0047\nEpoch 12/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -0.9230 - loss/inference_loss: -0.9230 - val_loss: -0.8459 - val_loss/inference_loss: -0.8459\nEpoch 13/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -0.9950 - loss/inference_loss: -0.9950 - val_loss: -1.1401 - val_loss/inference_loss: -1.1401\nEpoch 14/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.1003 - loss/inference_loss: -1.1003 - val_loss: -1.3110 - val_loss/inference_loss: -1.3110\nEpoch 15/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.1561 - loss/inference_loss: -1.1561 - val_loss: -1.3105 - val_loss/inference_loss: -1.3105\nEpoch 16/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - loss: -1.1491 - loss/inference_loss: -1.1491 - val_loss: -1.2032 - val_loss/inference_loss: -1.2032\nEpoch 17/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.1957 - loss/inference_loss: -1.1957 - val_loss: -1.3906 - val_loss/inference_loss: -1.3906\nEpoch 18/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.2044 - loss/inference_loss: -1.2044 - val_loss: -1.2953 - val_loss/inference_loss: -1.2953\nEpoch 19/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.2114 - loss/inference_loss: -1.2114 - val_loss: -1.2180 - val_loss/inference_loss: -1.2180\nEpoch 20/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.2200 - loss/inference_loss: -1.2200 - val_loss: -1.1664 - val_loss/inference_loss: -1.1664\nEpoch 21/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.2478 - loss/inference_loss: -1.2478 - val_loss: -1.3229 - val_loss/inference_loss: -1.3229\nEpoch 22/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.2740 - loss/inference_loss: -1.2740 - val_loss: -1.2695 - val_loss/inference_loss: -1.2695\nEpoch 23/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.2877 - loss/inference_loss: -1.2877 - val_loss: -1.2807 - val_loss/inference_loss: -1.2807\nEpoch 24/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3179 - loss/inference_loss: -1.3179 - val_loss: -1.2797 - val_loss/inference_loss: -1.2797\nEpoch 25/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3272 - loss/inference_loss: -1.3272 - val_loss: -1.3961 - val_loss/inference_loss: -1.3961\nEpoch 26/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3455 - loss/inference_loss: -1.3455 - val_loss: -1.2804 - val_loss/inference_loss: -1.2804\nEpoch 27/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3473 - loss/inference_loss: -1.3473 - val_loss: -1.4438 - val_loss/inference_loss: -1.4438\nEpoch 28/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3510 - loss/inference_loss: -1.3510 - val_loss: -1.4510 - val_loss/inference_loss: -1.4510\nEpoch 29/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3552 - loss/inference_loss: -1.3552 - val_loss: -1.4723 - val_loss/inference_loss: -1.4723\nEpoch 30/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3745 - loss/inference_loss: -1.3745 - val_loss: -1.3275 - val_loss/inference_loss: -1.3275\nEpoch 31/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - loss: -1.3644 - loss/inference_loss: -1.3644 - val_loss: -1.3631 - val_loss/inference_loss: -1.3631\nEpoch 32/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3738 - loss/inference_loss: -1.3738 - val_loss: -1.4041 - val_loss/inference_loss: -1.4041\nEpoch 33/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3902 - loss/inference_loss: -1.3902 - val_loss: -1.5244 - val_loss/inference_loss: -1.5244\nEpoch 34/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3940 - loss/inference_loss: -1.3940 - val_loss: -1.4587 - val_loss/inference_loss: -1.4587\nEpoch 35/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3896 - loss/inference_loss: -1.3896 - val_loss: -1.4295 - val_loss/inference_loss: -1.4295\nEpoch 36/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.3862 - loss/inference_loss: -1.3862 - val_loss: -1.4016 - val_loss/inference_loss: -1.4016\nEpoch 37/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - loss: -1.3927 - loss/inference_loss: -1.3927 - val_loss: -1.3490 - val_loss/inference_loss: -1.3490\nEpoch 38/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.3859 - loss/inference_loss: -1.3859 - val_loss: -1.4767 - val_loss/inference_loss: -1.4767\nEpoch 39/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4036 - loss/inference_loss: -1.4036 - val_loss: -1.4122 - val_loss/inference_loss: -1.4122\nEpoch 40/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4002 - loss/inference_loss: -1.4002 - val_loss: -1.4689 - val_loss/inference_loss: -1.4689\nEpoch 41/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4084 - loss/inference_loss: -1.4084 - val_loss: -1.5304 - val_loss/inference_loss: -1.5304\nEpoch 42/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.4136 - loss/inference_loss: -1.4136 - val_loss: -1.4460 - val_loss/inference_loss: -1.4460\nEpoch 43/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.4095 - loss/inference_loss: -1.4095 - val_loss: -1.5936 - val_loss/inference_loss: -1.5936\nEpoch 44/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4165 - loss/inference_loss: -1.4165 - val_loss: -1.3300 - val_loss/inference_loss: -1.3300\nEpoch 45/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4092 - loss/inference_loss: -1.4092 - val_loss: -1.4554 - val_loss/inference_loss: -1.4554\nEpoch 46/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4121 - loss/inference_loss: -1.4121 - val_loss: -1.4771 - val_loss/inference_loss: -1.4771\nEpoch 47/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4165 - loss/inference_loss: -1.4165 - val_loss: -1.3761 - val_loss/inference_loss: -1.3761\nEpoch 48/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4188 - loss/inference_loss: -1.4188 - val_loss: -1.4687 - val_loss/inference_loss: -1.4687\nEpoch 49/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - loss: -1.4108 - loss/inference_loss: -1.4108 - val_loss: -1.4455 - val_loss/inference_loss: -1.4455\nEpoch 50/50\n20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: -1.4162 - loss/inference_loss: -1.4162 - val_loss: -1.4218 - val_loss/inference_loss: -1.4218\ntest_data = simulator.sample(1_000)\nplots=workflow.plot_default_diagnostics(test_data=test_data)"
  },
  {
    "objectID": "exercises/bayesflow-diffusion.html#two-choice-task-racing-diffusion-model",
    "href": "exercises/bayesflow-diffusion.html#two-choice-task-racing-diffusion-model",
    "title": "Simple response time (Wald model)",
    "section": "Two choice task (Racing diffusion model)",
    "text": "Two choice task (Racing diffusion model)\nWe’ll assume a simple RDM with two choice alternatives (Tillman et al., 2020).\nHere we will simplify the model to include no bias, no variability in starting points. Instead of modeling one accumulator for each of [left, right] responses, we will simply model one accumulator for “incorrect” and one accumulator for “correct” response. This makes it a bit easier to simulate from (we do not need to simulate stimuli).\nThe model has four parameters: 2 drift rates (incorrect - \\(\\nu_0\\), correct \\(\\nu_1\\)), decision threshold \\(\\alpha\\), and non-decision time \\(\\tau\\).\n\ndef context(n=None):\n    if n is None:\n        n = np.random.randint(200, 351)\n    return dict(n=n)\n\ndef prior(nu=None, alpha=None, tau=None):\n    if nu is None:\n        nu=np.random.dirichlet([2, 2])\n        nu=np.random.gamma(shape=5, scale=0.5) * nu\n    if alpha is None:\n        alpha=np.random.gamma(shape=5, scale=0.2)\n    if tau is None:\n        tau=np.random.exponential(0.15)\n\n    return dict(nu=nu, alpha=alpha, tau=tau)\n\n# generate data for a single trial\ndef trial(nu, alpha, tau, max_t, dt):\n    response = -1\n    min_t = max_t\n    # loop over accumulators\n    # if an accumulator has a smaller passage time than the current minimum\n    # save it as the fastest accumulator (response)\n    for resp, drift in enumerate(nu):\n        t, evidence = evidence_accumulation(drift, max_t, dt)\n        passage = np.argmax(evidence &gt; alpha)\n        t = max_t if passage==0 else t[passage]\n        \n        if t &lt; min_t:\n            min_t = t\n            response = resp\n            \n    return min_t+tau, response\n\n# generate data for n trials\n# keep the data.shape always to max_n\n# the rest is filled with 0s\ndef likelihood(n, nu, alpha, tau, max_t=3.0, dt=0.02, max_n=350):\n    rt = np.zeros(max_n)\n    response = np.zeros(max_n)\n    observed = np.zeros(max_n)\n    for i in range(n):\n        result = trial(nu, alpha, tau, max_t, dt)\n        rt[i] = result[0]\n        response[i] = result[1]\n        observed[i] = 1\n\n    return dict(rt=rt, response=response, observed=observed)\n\nsimulator = bf.make_simulator([context, prior, likelihood])\n\n\nadapter = (bf.Adapter()\n    .as_set([\"rt\", \"response\", \"observed\"])\n    .constrain([\"nu\", \"alpha\", \"tau\"], lower=0)\n    .standardize(include=\"nu\",    mean= 0.7, std=1.2)\n    .standardize(include=\"alpha\", mean= 0.5, std=0.7)\n    .standardize(include=\"tau\",   mean=-2.5, std=1.3)\n    .concatenate([\"nu\", \"alpha\", \"tau\"], into=\"inference_variables\")\n    .concatenate([\"rt\", \"response\", \"observed\"], into=\"summary_variables\")\n    .rename(\"n\", \"inference_conditions\")\n)\n\n\nworkflow = bf.BasicWorkflow(\n    simulator = simulator,\n    adapter = adapter,\n    inference_network = bf.networks.CouplingFlow(\n        permutation=\"swap\", \n        subnet_kwargs=dict(dropout=False)\n    ),\n    summary_network=bf.networks.DeepSet(\n        base_distribution=\"normal\",\n        dropout=False\n    ),\n    inference_variables = [\"nu\", \"alpha\", \"tau\"],\n    inference_conditions = [\"n\"],\n    summary_variables = [\"rt\", \"response\", \"observed\"]\n)\n\n\ntrain_data = simulator.sample(5_000)\nvalidation_data = simulator.sample(1_000)\n\n\nhistory=workflow.fit_offline(\n    data=train_data, \n    epochs=100, \n    batch_size=250, \n    validation_data=validation_data\n)\n\nINFO:bayesflow:Fitting on dataset instance of OfflineDataset.\nINFO:bayesflow:Building on a test batch.\n\n\nEpoch 1/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 21s 570ms/step - loss: 20.9708 - loss/inference_loss: 20.6212 - loss/summary_loss: 0.3496 - val_loss: 6.4583 - val_loss/inference_loss: 6.3037 - val_loss/summary_loss: 0.1545\nEpoch 2/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 536ms/step - loss: 5.9631 - loss/inference_loss: 5.8166 - loss/summary_loss: 0.1465 - val_loss: 5.5611 - val_loss/inference_loss: 5.3896 - val_loss/summary_loss: 0.1715\nEpoch 3/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: 5.3252 - loss/inference_loss: 5.1295 - loss/summary_loss: 0.1957 - val_loss: 5.2970 - val_loss/inference_loss: 5.0639 - val_loss/summary_loss: 0.2331\nEpoch 4/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 553ms/step - loss: 4.7897 - loss/inference_loss: 4.6077 - loss/summary_loss: 0.1820 - val_loss: 4.8683 - val_loss/inference_loss: 4.6740 - val_loss/summary_loss: 0.1943\nEpoch 5/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 581ms/step - loss: 4.4792 - loss/inference_loss: 4.3138 - loss/summary_loss: 0.1654 - val_loss: 4.7738 - val_loss/inference_loss: 4.6027 - val_loss/summary_loss: 0.1711\nEpoch 6/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 554ms/step - loss: 4.3321 - loss/inference_loss: 4.1743 - loss/summary_loss: 0.1578 - val_loss: 4.7285 - val_loss/inference_loss: 4.5732 - val_loss/summary_loss: 0.1553\nEpoch 7/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 585ms/step - loss: 4.5421 - loss/inference_loss: 4.3665 - loss/summary_loss: 0.1756 - val_loss: 4.1935 - val_loss/inference_loss: 3.9998 - val_loss/summary_loss: 0.1937\nEpoch 8/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 572ms/step - loss: 4.2988 - loss/inference_loss: 4.1162 - loss/summary_loss: 0.1826 - val_loss: 4.1436 - val_loss/inference_loss: 3.9832 - val_loss/summary_loss: 0.1604\nEpoch 9/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 572ms/step - loss: 3.9947 - loss/inference_loss: 3.8410 - loss/summary_loss: 0.1537 - val_loss: 3.8679 - val_loss/inference_loss: 3.6978 - val_loss/summary_loss: 0.1701\nEpoch 10/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 565ms/step - loss: 3.8380 - loss/inference_loss: 3.6859 - loss/summary_loss: 0.1521 - val_loss: 3.7873 - val_loss/inference_loss: 3.6242 - val_loss/summary_loss: 0.1631\nEpoch 11/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 568ms/step - loss: 3.9673 - loss/inference_loss: 3.8106 - loss/summary_loss: 0.1567 - val_loss: 3.6799 - val_loss/inference_loss: 3.5074 - val_loss/summary_loss: 0.1725\nEpoch 12/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 571ms/step - loss: 4.0578 - loss/inference_loss: 3.8796 - loss/summary_loss: 0.1782 - val_loss: 3.7456 - val_loss/inference_loss: 3.5423 - val_loss/summary_loss: 0.2033\nEpoch 13/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 566ms/step - loss: 3.6058 - loss/inference_loss: 3.4265 - loss/summary_loss: 0.1794 - val_loss: 3.3420 - val_loss/inference_loss: 3.1763 - val_loss/summary_loss: 0.1657\nEpoch 14/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 568ms/step - loss: 3.4954 - loss/inference_loss: 3.3371 - loss/summary_loss: 0.1583 - val_loss: 3.8457 - val_loss/inference_loss: 3.6819 - val_loss/summary_loss: 0.1638\nEpoch 15/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 569ms/step - loss: 3.5513 - loss/inference_loss: 3.3970 - loss/summary_loss: 0.1543 - val_loss: 3.9955 - val_loss/inference_loss: 3.8269 - val_loss/summary_loss: 0.1686\nEpoch 16/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 579ms/step - loss: 3.4844 - loss/inference_loss: 3.3220 - loss/summary_loss: 0.1624 - val_loss: 3.5121 - val_loss/inference_loss: 3.3520 - val_loss/summary_loss: 0.1601\nEpoch 17/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 578ms/step - loss: 3.2603 - loss/inference_loss: 3.1055 - loss/summary_loss: 0.1548 - val_loss: 3.3735 - val_loss/inference_loss: 3.2034 - val_loss/summary_loss: 0.1702\nEpoch 18/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 586ms/step - loss: 3.0964 - loss/inference_loss: 2.9365 - loss/summary_loss: 0.1599 - val_loss: 3.5813 - val_loss/inference_loss: 3.4131 - val_loss/summary_loss: 0.1682\nEpoch 19/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 568ms/step - loss: 2.9846 - loss/inference_loss: 2.8216 - loss/summary_loss: 0.1629 - val_loss: 2.9246 - val_loss/inference_loss: 2.7537 - val_loss/summary_loss: 0.1709\nEpoch 20/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: 2.9375 - loss/inference_loss: 2.7749 - loss/summary_loss: 0.1626 - val_loss: 2.8463 - val_loss/inference_loss: 2.6795 - val_loss/summary_loss: 0.1668\nEpoch 21/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 558ms/step - loss: 2.8605 - loss/inference_loss: 2.6985 - loss/summary_loss: 0.1620 - val_loss: 2.5638 - val_loss/inference_loss: 2.3841 - val_loss/summary_loss: 0.1796\nEpoch 22/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 577ms/step - loss: 2.8183 - loss/inference_loss: 2.6561 - loss/summary_loss: 0.1622 - val_loss: 3.1124 - val_loss/inference_loss: 2.9541 - val_loss/summary_loss: 0.1583\nEpoch 23/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 573ms/step - loss: 2.7191 - loss/inference_loss: 2.5615 - loss/summary_loss: 0.1575 - val_loss: 2.6894 - val_loss/inference_loss: 2.5268 - val_loss/summary_loss: 0.1626\nEpoch 24/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 577ms/step - loss: 2.6972 - loss/inference_loss: 2.5380 - loss/summary_loss: 0.1593 - val_loss: 2.8283 - val_loss/inference_loss: 2.6653 - val_loss/summary_loss: 0.1629\nEpoch 25/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 573ms/step - loss: 2.6366 - loss/inference_loss: 2.4786 - loss/summary_loss: 0.1580 - val_loss: 2.4028 - val_loss/inference_loss: 2.2342 - val_loss/summary_loss: 0.1686\nEpoch 26/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 584ms/step - loss: 2.5273 - loss/inference_loss: 2.3641 - loss/summary_loss: 0.1631 - val_loss: 3.2753 - val_loss/inference_loss: 3.1085 - val_loss/summary_loss: 0.1669\nEpoch 27/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 552ms/step - loss: 2.5849 - loss/inference_loss: 2.4246 - loss/summary_loss: 0.1604 - val_loss: 2.7328 - val_loss/inference_loss: 2.5645 - val_loss/summary_loss: 0.1684\nEpoch 28/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 544ms/step - loss: 2.4469 - loss/inference_loss: 2.2853 - loss/summary_loss: 0.1616 - val_loss: 2.4741 - val_loss/inference_loss: 2.3143 - val_loss/summary_loss: 0.1597\nEpoch 29/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 544ms/step - loss: 2.3149 - loss/inference_loss: 2.1566 - loss/summary_loss: 0.1584 - val_loss: 2.0014 - val_loss/inference_loss: 1.8472 - val_loss/summary_loss: 0.1542\nEpoch 30/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: 2.3523 - loss/inference_loss: 2.1965 - loss/summary_loss: 0.1558 - val_loss: 2.6232 - val_loss/inference_loss: 2.4516 - val_loss/summary_loss: 0.1716\nEpoch 31/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 543ms/step - loss: 2.3384 - loss/inference_loss: 2.1854 - loss/summary_loss: 0.1530 - val_loss: 2.3379 - val_loss/inference_loss: 2.1691 - val_loss/summary_loss: 0.1688\nEpoch 32/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 550ms/step - loss: 2.2515 - loss/inference_loss: 2.0954 - loss/summary_loss: 0.1561 - val_loss: 2.3814 - val_loss/inference_loss: 2.2284 - val_loss/summary_loss: 0.1530\nEpoch 33/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 541ms/step - loss: 2.1215 - loss/inference_loss: 1.9579 - loss/summary_loss: 0.1636 - val_loss: 2.0887 - val_loss/inference_loss: 1.9297 - val_loss/summary_loss: 0.1590\nEpoch 34/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 540ms/step - loss: 2.1897 - loss/inference_loss: 2.0323 - loss/summary_loss: 0.1574 - val_loss: 2.4066 - val_loss/inference_loss: 2.2340 - val_loss/summary_loss: 0.1725\nEpoch 35/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 584ms/step - loss: 1.8850 - loss/inference_loss: 1.7289 - loss/summary_loss: 0.1561 - val_loss: 1.6007 - val_loss/inference_loss: 1.4405 - val_loss/summary_loss: 0.1602\nEpoch 36/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 566ms/step - loss: 1.7409 - loss/inference_loss: 1.5707 - loss/summary_loss: 0.1701 - val_loss: 1.8780 - val_loss/inference_loss: 1.7130 - val_loss/summary_loss: 0.1650\nEpoch 37/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 570ms/step - loss: 2.3168 - loss/inference_loss: 2.1430 - loss/summary_loss: 0.1738 - val_loss: 1.8696 - val_loss/inference_loss: 1.7035 - val_loss/summary_loss: 0.1660\nEpoch 38/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 567ms/step - loss: 1.6114 - loss/inference_loss: 1.4466 - loss/summary_loss: 0.1649 - val_loss: 1.2581 - val_loss/inference_loss: 1.0754 - val_loss/summary_loss: 0.1827\nEpoch 39/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 580ms/step - loss: 1.5048 - loss/inference_loss: 1.3375 - loss/summary_loss: 0.1673 - val_loss: 1.6852 - val_loss/inference_loss: 1.5086 - val_loss/summary_loss: 0.1766\nEpoch 40/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 568ms/step - loss: 1.3536 - loss/inference_loss: 1.1865 - loss/summary_loss: 0.1670 - val_loss: 1.7820 - val_loss/inference_loss: 1.6051 - val_loss/summary_loss: 0.1769\nEpoch 41/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 580ms/step - loss: 1.6882 - loss/inference_loss: 1.5211 - loss/summary_loss: 0.1671 - val_loss: 2.0654 - val_loss/inference_loss: 1.8773 - val_loss/summary_loss: 0.1880\nEpoch 42/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 597ms/step - loss: 1.4865 - loss/inference_loss: 1.2806 - loss/summary_loss: 0.2059 - val_loss: 1.4813 - val_loss/inference_loss: 1.2312 - val_loss/summary_loss: 0.2501\nEpoch 43/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 567ms/step - loss: 1.2900 - loss/inference_loss: 1.0658 - loss/summary_loss: 0.2242 - val_loss: 1.0590 - val_loss/inference_loss: 0.8564 - val_loss/summary_loss: 0.2026\nEpoch 44/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: 1.0724 - loss/inference_loss: 0.8845 - loss/summary_loss: 0.1879 - val_loss: 1.6218 - val_loss/inference_loss: 1.4355 - val_loss/summary_loss: 0.1862\nEpoch 45/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 593ms/step - loss: 1.2824 - loss/inference_loss: 1.0915 - loss/summary_loss: 0.1908 - val_loss: 1.2253 - val_loss/inference_loss: 1.0222 - val_loss/summary_loss: 0.2031\nEpoch 46/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 12s 580ms/step - loss: 1.0173 - loss/inference_loss: 0.8328 - loss/summary_loss: 0.1845 - val_loss: 1.2865 - val_loss/inference_loss: 1.0725 - val_loss/summary_loss: 0.2140\nEpoch 47/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 565ms/step - loss: 1.1920 - loss/inference_loss: 1.0173 - loss/summary_loss: 0.1747 - val_loss: 0.6424 - val_loss/inference_loss: 0.4737 - val_loss/summary_loss: 0.1688\nEpoch 48/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: 0.9623 - loss/inference_loss: 0.7910 - loss/summary_loss: 0.1713 - val_loss: 0.9176 - val_loss/inference_loss: 0.7322 - val_loss/summary_loss: 0.1853\nEpoch 49/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 543ms/step - loss: 0.8234 - loss/inference_loss: 0.6522 - loss/summary_loss: 0.1712 - val_loss: 0.5328 - val_loss/inference_loss: 0.3686 - val_loss/summary_loss: 0.1641\nEpoch 50/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 540ms/step - loss: 0.7788 - loss/inference_loss: 0.6058 - loss/summary_loss: 0.1730 - val_loss: 1.4526 - val_loss/inference_loss: 1.2618 - val_loss/summary_loss: 0.1908\nEpoch 51/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 542ms/step - loss: 1.0559 - loss/inference_loss: 0.8846 - loss/summary_loss: 0.1712 - val_loss: 1.0322 - val_loss/inference_loss: 0.8620 - val_loss/summary_loss: 0.1703\nEpoch 52/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 541ms/step - loss: 0.9098 - loss/inference_loss: 0.7380 - loss/summary_loss: 0.1719 - val_loss: 0.6960 - val_loss/inference_loss: 0.5214 - val_loss/summary_loss: 0.1746\nEpoch 53/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: 0.7205 - loss/inference_loss: 0.5472 - loss/summary_loss: 0.1733 - val_loss: 0.6936 - val_loss/inference_loss: 0.5190 - val_loss/summary_loss: 0.1746\nEpoch 54/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 542ms/step - loss: 0.5575 - loss/inference_loss: 0.3812 - loss/summary_loss: 0.1764 - val_loss: 0.2826 - val_loss/inference_loss: 0.1146 - val_loss/summary_loss: 0.1680\nEpoch 55/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 541ms/step - loss: 0.5075 - loss/inference_loss: 0.3318 - loss/summary_loss: 0.1758 - val_loss: 0.4397 - val_loss/inference_loss: 0.2523 - val_loss/summary_loss: 0.1874\nEpoch 56/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: 0.5964 - loss/inference_loss: 0.4199 - loss/summary_loss: 0.1766 - val_loss: 0.5362 - val_loss/inference_loss: 0.3637 - val_loss/summary_loss: 0.1725\nEpoch 57/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: 0.9508 - loss/inference_loss: 0.7791 - loss/summary_loss: 0.1717 - val_loss: 0.6182 - val_loss/inference_loss: 0.4515 - val_loss/summary_loss: 0.1667\nEpoch 58/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 542ms/step - loss: 0.5039 - loss/inference_loss: 0.3291 - loss/summary_loss: 0.1748 - val_loss: 0.2156 - val_loss/inference_loss: 0.0316 - val_loss/summary_loss: 0.1840\nEpoch 59/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 542ms/step - loss: 0.6430 - loss/inference_loss: 0.4713 - loss/summary_loss: 0.1717 - val_loss: 0.4248 - val_loss/inference_loss: 0.2376 - val_loss/summary_loss: 0.1872\nEpoch 60/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 542ms/step - loss: 0.4375 - loss/inference_loss: 0.2643 - loss/summary_loss: 0.1731 - val_loss: 0.5216 - val_loss/inference_loss: 0.3502 - val_loss/summary_loss: 0.1714\nEpoch 61/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 554ms/step - loss: 0.5149 - loss/inference_loss: 0.3437 - loss/summary_loss: 0.1711 - val_loss: 0.6297 - val_loss/inference_loss: 0.4741 - val_loss/summary_loss: 0.1556\nEpoch 62/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 550ms/step - loss: 0.3302 - loss/inference_loss: 0.1708 - loss/summary_loss: 0.1594 - val_loss: 0.3909 - val_loss/inference_loss: 0.2277 - val_loss/summary_loss: 0.1632\nEpoch 63/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: 0.3983 - loss/inference_loss: 0.2339 - loss/summary_loss: 0.1643 - val_loss: 0.5141 - val_loss/inference_loss: 0.3284 - val_loss/summary_loss: 0.1857\nEpoch 64/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: 0.2731 - loss/inference_loss: 0.1049 - loss/summary_loss: 0.1681 - val_loss: 0.1909 - val_loss/inference_loss: 0.0234 - val_loss/summary_loss: 0.1675\nEpoch 65/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: 0.2533 - loss/inference_loss: 0.0882 - loss/summary_loss: 0.1651 - val_loss: 0.3606 - val_loss/inference_loss: 0.1868 - val_loss/summary_loss: 0.1737\nEpoch 66/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 544ms/step - loss: 0.2249 - loss/inference_loss: 0.0612 - loss/summary_loss: 0.1637 - val_loss: 0.6684 - val_loss/inference_loss: 0.5002 - val_loss/summary_loss: 0.1682\nEpoch 67/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 544ms/step - loss: 0.2323 - loss/inference_loss: 0.0717 - loss/summary_loss: 0.1605 - val_loss: 0.2420 - val_loss/inference_loss: 0.0885 - val_loss/summary_loss: 0.1535\nEpoch 68/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: 0.1380 - loss/inference_loss: -0.0215 - loss/summary_loss: 0.1595 - val_loss: -0.1493 - val_loss/inference_loss: -0.3209 - val_loss/summary_loss: 0.1715\nEpoch 69/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: 0.1005 - loss/inference_loss: -0.0615 - loss/summary_loss: 0.1620 - val_loss: 0.2482 - val_loss/inference_loss: 0.0915 - val_loss/summary_loss: 0.1567\nEpoch 70/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 553ms/step - loss: 0.1835 - loss/inference_loss: 0.0197 - loss/summary_loss: 0.1638 - val_loss: 0.4854 - val_loss/inference_loss: 0.3127 - val_loss/summary_loss: 0.1727\nEpoch 71/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: 0.1100 - loss/inference_loss: -0.0533 - loss/summary_loss: 0.1633 - val_loss: 0.2090 - val_loss/inference_loss: 0.0429 - val_loss/summary_loss: 0.1661\nEpoch 72/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 560ms/step - loss: 0.0443 - loss/inference_loss: -0.1226 - loss/summary_loss: 0.1669 - val_loss: 0.1434 - val_loss/inference_loss: -0.0256 - val_loss/summary_loss: 0.1690\nEpoch 73/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 554ms/step - loss: 0.0536 - loss/inference_loss: -0.1134 - loss/summary_loss: 0.1670 - val_loss: 0.1843 - val_loss/inference_loss: 0.0194 - val_loss/summary_loss: 0.1649\nEpoch 74/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: 0.0409 - loss/inference_loss: -0.1268 - loss/summary_loss: 0.1677 - val_loss: 0.1043 - val_loss/inference_loss: -0.0714 - val_loss/summary_loss: 0.1758\nEpoch 75/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: 0.0519 - loss/inference_loss: -0.1139 - loss/summary_loss: 0.1659 - val_loss: 0.2015 - val_loss/inference_loss: 0.0364 - val_loss/summary_loss: 0.1651\nEpoch 76/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 550ms/step - loss: -9.3351e-04 - loss/inference_loss: -0.1657 - loss/summary_loss: 0.1648 - val_loss: 0.1912 - val_loss/inference_loss: -0.0046 - val_loss/summary_loss: 0.1958\nEpoch 77/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: -0.0163 - loss/inference_loss: -0.1815 - loss/summary_loss: 0.1652 - val_loss: 0.0029 - val_loss/inference_loss: -0.1616 - val_loss/summary_loss: 0.1646\nEpoch 78/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: -0.0676 - loss/inference_loss: -0.2336 - loss/summary_loss: 0.1660 - val_loss: 0.0314 - val_loss/inference_loss: -0.1420 - val_loss/summary_loss: 0.1734\nEpoch 79/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: -0.1293 - loss/inference_loss: -0.2922 - loss/summary_loss: 0.1628 - val_loss: -0.0265 - val_loss/inference_loss: -0.1853 - val_loss/summary_loss: 0.1588\nEpoch 80/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 548ms/step - loss: -0.1306 - loss/inference_loss: -0.2919 - loss/summary_loss: 0.1613 - val_loss: -0.1537 - val_loss/inference_loss: -0.3320 - val_loss/summary_loss: 0.1783\nEpoch 81/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 556ms/step - loss: -0.1184 - loss/inference_loss: -0.2816 - loss/summary_loss: 0.1632 - val_loss: -0.3627 - val_loss/inference_loss: -0.5255 - val_loss/summary_loss: 0.1629\nEpoch 82/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: -0.1359 - loss/inference_loss: -0.2981 - loss/summary_loss: 0.1621 - val_loss: 0.1000 - val_loss/inference_loss: -0.0440 - val_loss/summary_loss: 0.1440\nEpoch 83/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: -0.1611 - loss/inference_loss: -0.3231 - loss/summary_loss: 0.1620 - val_loss: -0.0432 - val_loss/inference_loss: -0.1958 - val_loss/summary_loss: 0.1526\nEpoch 84/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 548ms/step - loss: -0.1888 - loss/inference_loss: -0.3505 - loss/summary_loss: 0.1617 - val_loss: 0.2523 - val_loss/inference_loss: 0.0854 - val_loss/summary_loss: 0.1670\nEpoch 85/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 551ms/step - loss: -0.1954 - loss/inference_loss: -0.3547 - loss/summary_loss: 0.1593 - val_loss: -0.2561 - val_loss/inference_loss: -0.4276 - val_loss/summary_loss: 0.1715\nEpoch 86/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 549ms/step - loss: -0.1764 - loss/inference_loss: -0.3366 - loss/summary_loss: 0.1602 - val_loss: -0.1960 - val_loss/inference_loss: -0.3549 - val_loss/summary_loss: 0.1589\nEpoch 87/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 555ms/step - loss: -0.2151 - loss/inference_loss: -0.3746 - loss/summary_loss: 0.1594 - val_loss: -0.0779 - val_loss/inference_loss: -0.2426 - val_loss/summary_loss: 0.1647\nEpoch 88/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: -0.2131 - loss/inference_loss: -0.3725 - loss/summary_loss: 0.1594 - val_loss: -0.1772 - val_loss/inference_loss: -0.3338 - val_loss/summary_loss: 0.1566\nEpoch 89/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 550ms/step - loss: -0.2434 - loss/inference_loss: -0.4029 - loss/summary_loss: 0.1595 - val_loss: -0.1916 - val_loss/inference_loss: -0.3591 - val_loss/summary_loss: 0.1674\nEpoch 90/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 551ms/step - loss: -0.2553 - loss/inference_loss: -0.4132 - loss/summary_loss: 0.1579 - val_loss: -0.1315 - val_loss/inference_loss: -0.2902 - val_loss/summary_loss: 0.1587\nEpoch 91/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 548ms/step - loss: -0.2574 - loss/inference_loss: -0.4158 - loss/summary_loss: 0.1584 - val_loss: 0.1010 - val_loss/inference_loss: -0.0772 - val_loss/summary_loss: 0.1782\nEpoch 92/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: -0.2710 - loss/inference_loss: -0.4296 - loss/summary_loss: 0.1586 - val_loss: -0.2252 - val_loss/inference_loss: -0.3775 - val_loss/summary_loss: 0.1523\nEpoch 93/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 551ms/step - loss: -0.2747 - loss/inference_loss: -0.4330 - loss/summary_loss: 0.1583 - val_loss: -0.0979 - val_loss/inference_loss: -0.2547 - val_loss/summary_loss: 0.1568\nEpoch 94/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 555ms/step - loss: -0.2738 - loss/inference_loss: -0.4320 - loss/summary_loss: 0.1582 - val_loss: -0.1712 - val_loss/inference_loss: -0.3199 - val_loss/summary_loss: 0.1487\nEpoch 95/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 544ms/step - loss: -0.2758 - loss/inference_loss: -0.4329 - loss/summary_loss: 0.1571 - val_loss: 0.0891 - val_loss/inference_loss: -0.0787 - val_loss/summary_loss: 0.1678\nEpoch 96/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: -0.2836 - loss/inference_loss: -0.4420 - loss/summary_loss: 0.1584 - val_loss: -0.1718 - val_loss/inference_loss: -0.3436 - val_loss/summary_loss: 0.1718\nEpoch 97/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: -0.2792 - loss/inference_loss: -0.4364 - loss/summary_loss: 0.1572 - val_loss: -0.0414 - val_loss/inference_loss: -0.2135 - val_loss/summary_loss: 0.1721\nEpoch 98/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 546ms/step - loss: -0.2923 - loss/inference_loss: -0.4494 - loss/summary_loss: 0.1571 - val_loss: 0.1190 - val_loss/inference_loss: -0.0561 - val_loss/summary_loss: 0.1751\nEpoch 99/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 547ms/step - loss: -0.2900 - loss/inference_loss: -0.4485 - loss/summary_loss: 0.1585 - val_loss: -0.1284 - val_loss/inference_loss: -0.2807 - val_loss/summary_loss: 0.1523\nEpoch 100/100\n20/20 ━━━━━━━━━━━━━━━━━━━━ 11s 545ms/step - loss: -0.2960 - loss/inference_loss: -0.4526 - loss/summary_loss: 0.1565 - val_loss: -0.2876 - val_loss/inference_loss: -0.4450 - val_loss/summary_loss: 0.1574\n\n\n\ntest_data = simulator.sample(1_000)\nplots=workflow.plot_default_diagnostics(test_data=test_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplication to real data\nHere we will work with data from Fortmann, et al. (2008), that is also included in the R package EMC2 (Stevenson, Donzallaz, & Heathcote, 2025). Here we use a slightly reshaped dataset where each combination of subject x condition is extended to a length of 350 trials (the missing trials are filled with 0s). This allows us to estimate the posterior for each subject in each condition with a single pass through the posterior approximator.\n\ndata_inference = pd.read_csv(\"../data/forstmann.csv\")\n\n\ndata_inference_grouped = data_inference.groupby([\"subject\", \"condition\"])\n\n\ndata_inference_dict = {\n    key: np.array([group[key].values.reshape(350, 1) for _, group in data_inference_grouped]) \n             for key in ['rt', 'response', 'observed']}\ndata_inference_dict[\"n\"] = np.sum(data_inference_dict[\"observed\"], axis=1)\nprint({key: value.shape for key, value in data_inference_dict.items()})\n\n{'rt': (57, 350, 1), 'response': (57, 350, 1), 'observed': (57, 350, 1), 'n': (57, 1)}\n\n\n\nposterior_samples = workflow.sample(conditions=data_inference_dict, num_samples=1_000)\n\n\n# pick the first participant, first condition\nposterior = {key: value[0] for key, value in posterior_samples.items()}\ndata = data_inference_grouped.get_group(('as1t', 'accuracy'))\n\n\nf=bf.diagnostics.pairs_posterior(estimates=posterior)\n\n\n\n\n\n\n\n\n\ndef ecdf(rt, response, observed, **kwargs):\n    observed_mask = (observed == 1)\n    response_0_mask = ((response == 0) & observed_mask)\n    response_1_mask = ((response == 1) & observed_mask)\n\n    response_0_prop = np.sum(response_0_mask) / np.sum(observed_mask)\n    response_1_prop = np.sum(response_1_mask) / np.sum(observed_mask)\n\n    response_0_ecdf = stats.ecdf(rt[response_0_mask]).cdf\n    response_0_ecdf = response_0_prop * response_0_ecdf.evaluate(np.linspace(0, 1, 101))\n\n    response_1_ecdf = stats.ecdf(rt[response_1_mask]).cdf\n    response_1_ecdf = response_1_prop * response_1_ecdf.evaluate(np.linspace(0, 1, 101))\n\n    return response_0_ecdf, response_1_ecdf\n    \n\n\nplot_data = ecdf(**data)\n\n\nposterior_predictives = simulator.sample(1000, **posterior)\n\n/var/folders/vn/tvq3_rgx63795x08zmwtn_rr0000gn/T/ipykernel_15834/1207014727.py:44: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  rt[i] = result[0]\n\n\n\nplot_data_predictive = []\nfor i in range(1000):\n    x = { key: value[i:i+1,...] for key, value in posterior_predictives.items()}\n    plot_data_predictive.append(ecdf(**x))\nplot_data_predictive = np.array(plot_data_predictive)\n\n\nplot_data_quantiles = np.quantile(\n    plot_data_predictive, \n    q = [0.25, 0.5, 0.75],\n    axis=0\n)\nplot_data_quantiles.shape\n\n(3, 2, 101)\n\n\n\nt = np.linspace(0, 1, 101)\ncols = [\"red\", \"blue\"]\nfor i, lab in enumerate([\"Incorrect\", \"Correct\"]):\n    plt.plot(t, plot_data[i], label=lab, color=cols[i])\n    plt.plot(t, plot_data_quantiles[1, i, :], color=cols[i], alpha=0.5, label=\"median predictive\")\n    plt.fill_between(\n        t,\n        plot_data_quantiles[0,  i,:],\n        plot_data_quantiles[-1, i,:],\n        label=\"50% predictive interval\",\n        color=cols[i],\n        alpha=0.3\n    )\nf=plt.legend()"
  },
  {
    "objectID": "exercises/bayesflow-diffusion.html#references",
    "href": "exercises/bayesflow-diffusion.html#references",
    "title": "Simple response time (Wald model)",
    "section": "References",
    "text": "References\nAnders, R., Alario, F., & Van Maanen, L. (2016). The shifted Wald distribution for response time data analysis. Psychological methods, 21(3), 309.\nForstmann, B. U., Dutilh, G., Brown, S., Neumann, J., Von Cramon, D. Y., Ridderinkhof, K. R., & Wagenmakers, E. J. (2008). Striatum and pre-SMA facilitate decision-making under time pressure. Proceedings of the National Academy of Sciences, 105(45), 17538-17542.\nStevenson N., Donzallaz M., Heathcote A. (2025). EMC2: Bayesian Hierarchical Analysis of Cognitive Models of Choice. R package version 3.1.0, https://github.com/ampl-psych/emc2.\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability: The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27(5), 911-936."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "slides/intro.html#section",
    "href": "slides/intro.html#section",
    "title": "Amortized Bayesian Inference",
    "section": "",
    "text": "Artificial Intelligence has two goals. First, AI is directed toward getting computers to be smart and do smart things so that human beings don’t have to do them. And second, AI […] is also directed at using computers to simulate human beings, so that we can find out how humans work.\n\nSimon (1983, p. 27), van Rooij et al. (2024)"
  },
  {
    "objectID": "slides/intro.html#parameter-estimation",
    "href": "slides/intro.html#parameter-estimation",
    "title": "Amortized Bayesian Inference",
    "section": "Parameter estimation",
    "text": "Parameter estimation\nWhat are the values of the model parameters \\(\\theta\\), given observed data \\(x\\)?\nBayes’ theorem\n\\[\n\\begin{aligned}\np(\\theta \\mid x) & = \\frac{p(\\theta, x)}{p(x)} \\\\\n& = \\frac{p(\\theta) \\times p(x \\mid \\theta)}{\\int p(\\theta) \\times p(x \\mid \\theta) d\\theta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/intro.html#marginal-likelihood",
    "href": "slides/intro.html#marginal-likelihood",
    "title": "Amortized Bayesian Inference",
    "section": "Marginal likelihood",
    "text": "Marginal likelihood\n\\[\np(x) = \\int p(\\theta) \\times p(x \\mid \\theta) d\\theta\n\\]\n\ndifficult to evaluate\noften intractable"
  },
  {
    "objectID": "slides/intro.html#classic-alternatives",
    "href": "slides/intro.html#classic-alternatives",
    "title": "Amortized Bayesian Inference",
    "section": "Classic alternatives",
    "text": "Classic alternatives\n\nApproximate \\(p(\\theta \\mid x)\\)\n\nMarkov Chain Monte Carlo (MCMC): \\(\\theta \\propto p(\\theta) \\times p(x \\mid \\theta)\\)\n\nObtain point estimates:\n\nMaximum likelihood: \\(\\hat{\\theta} = \\operatorname*{argmax}_{\\theta} p(x \\mid \\theta)\\)\nMaximum aposteriori: \\(\\hat{\\theta} = \\operatorname*{argmax}_{\\theta} p(\\theta) \\times p(x \\mid \\theta)\\)\n\nNone of the methods require \\(p(x)\\)\nBut all require evaluating \\(p(x \\mid \\theta)\\)"
  },
  {
    "objectID": "slides/intro.html#simulation-based-inference-sbi",
    "href": "slides/intro.html#simulation-based-inference-sbi",
    "title": "Amortized Bayesian Inference",
    "section": "Simulation-based inference (SBI)",
    "text": "Simulation-based inference (SBI)\n\n“Likelihood-free”\nCannot evaluate \\(p(x \\mid \\theta)\\) or \\(p(\\theta)\\)\nApproximate using sampling\n\nExamples\n\nSurrogate Likelihood\nRejection Sampling\nApproximate Bayesian Computation\n\nModern overview: Cranmer et al. (2020)"
  },
  {
    "objectID": "slides/intro.html#surrogate-likelihood",
    "href": "slides/intro.html#surrogate-likelihood",
    "title": "Amortized Bayesian Inference",
    "section": "Surrogate likelihood",
    "text": "Surrogate likelihood\n\nFor a given parameter value \\(\\theta\\), simulate many samples of \\(x\\)\nEstimate the density \\(p(x\\mid\\theta)\\) (e.g., kernel density estimation)\n\nUsed for approximate MLE/MAP, or within MCMC"
  },
  {
    "objectID": "slides/intro.html#rejection-sampling",
    "href": "slides/intro.html#rejection-sampling",
    "title": "Amortized Bayesian Inference",
    "section": "Rejection sampling",
    "text": "Rejection sampling\n\\[\n\\begin{aligned}\np(\\theta, x) & = p(\\theta) p(x \\mid \\theta)\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/intro.html#rejection-sampling-1",
    "href": "slides/intro.html#rejection-sampling-1",
    "title": "Amortized Bayesian Inference",
    "section": "Rejection sampling",
    "text": "Rejection sampling\n\\[\n\\begin{aligned}\np(\\theta, x) & = p(\\theta) p(x \\mid \\theta)\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/intro.html#rejection-sampling-2",
    "href": "slides/intro.html#rejection-sampling-2",
    "title": "Amortized Bayesian Inference",
    "section": "Rejection sampling",
    "text": "Rejection sampling\n\\[\n\\begin{aligned}\n\\theta^{(s)} & \\sim \\text{Beta}(1, 1)\\\\\nx^{(s)} &\\sim \\text{Binomial}(\\theta^{(s)}, 10)\\\\\n\\\\[0.1em]\n\\theta \\mid x^{\\text{obs}}=7 & \\approx \\text{Samples from } \\theta^{(s)} \\text{ where } x^{(s)} = 7\n\\end{aligned}\n\\]\n\n\nPython\n\nprior = np.random.beta(1, 1, size=5000)\nx = np.random.binomial(n=10, p=prior)\n\nobserved = 7\nposterior = prior[x == observed]"
  },
  {
    "objectID": "slides/intro.html#approximate-bayesian-computation-abc",
    "href": "slides/intro.html#approximate-bayesian-computation-abc",
    "title": "Amortized Bayesian Inference",
    "section": "Approximate Bayesian Computation (ABC)",
    "text": "Approximate Bayesian Computation (ABC)\n\nGeneralization of rejection sampling\nGiven a sampled parameter value \\(\\theta\\), generate a data set \\(x\\)\nCompare the simulated data set to observed \\(x^{\\text{obs}}\\)\nRetain the parameter if the data sets are not too dissimilar\n\n\\[\n\\rho(s(x), s(x^{\\text{obs}})) \\leq \\epsilon\n\\]"
  },
  {
    "objectID": "slides/intro.html#issues",
    "href": "slides/intro.html#issues",
    "title": "Amortized Bayesian Inference",
    "section": "Issues",
    "text": "Issues\n\nCurse of dimensionality\nComputationally expensive\nHandcrafted summary statistics"
  },
  {
    "objectID": "slides/intro.html#neural-estimation",
    "href": "slides/intro.html#neural-estimation",
    "title": "Amortized Bayesian Inference",
    "section": "Neural estimation",
    "text": "Neural estimation\n\nApproximate using generative neural networks\n\nDeep learning architecture that approximates a probability distribution\n\n\n\n\n\nNeural likelihood estimation (NLE)\n\nLearn \\(p(x \\mid \\theta)\\)\nSurrogate likelihood\n\n\nNeural posterior estimation (NPE)\n\nLearn \\(p(\\theta \\mid x)\\)\nObtain posterior directly"
  },
  {
    "objectID": "slides/intro.html#amortized-bayesian-inference-abi",
    "href": "slides/intro.html#amortized-bayesian-inference-abi",
    "title": "Amortized Bayesian Inference",
    "section": "Amortized Bayesian Inference (ABI)",
    "text": "Amortized Bayesian Inference (ABI)\n\nGenerative neural networks\n\nProduce a distribution \\(q(\\theta \\mid x)\\)\n\nTrain them on simulated pairs \\((\\theta^{(s)}, x^{(s)}) \\sim p(\\theta, x)\\)\n\nLearn \\(q(\\theta \\mid x) \\approx p(\\theta \\mid x)\\)\n\nOnce trained, can be used on observed data \\(x^\\text{obs}\\)\n\n\\(q(\\theta \\mid x^\\text{obs}) \\approx p(\\theta \\mid x^\\text{obs})\\)"
  },
  {
    "objectID": "slides/intro.html#amortized-bayesian-inference-abi-1",
    "href": "slides/intro.html#amortized-bayesian-inference-abi-1",
    "title": "Amortized Bayesian Inference",
    "section": "Amortized Bayesian Inference (ABI)",
    "text": "Amortized Bayesian Inference (ABI)\nPay the cost of inference upfront during training, receive benefits later\n\n\nTraining\n\nTrain neural networks\nSimulated data and parameters\nLearn the maping between data and parameters\nSlow, resource consuming process\n\n\nInference\n\nApply pretrained networks\nObserved data\nPosterior distribution of parameters\nFast, cheap process"
  },
  {
    "objectID": "slides/intro.html#amortized-bayesian-inference-abi-2",
    "href": "slides/intro.html#amortized-bayesian-inference-abi-2",
    "title": "Amortized Bayesian Inference",
    "section": "Amortized Bayesian Inference (ABI)",
    "text": "Amortized Bayesian Inference (ABI)\nUsing deep learning generative neural networks to make Bayesian inference.\n\n\n\nAdvantages\n\nFast inference\nSimulation based – intractable models\n\n\nDisatvantages\n\nNeed for training\nSimulation based – weaker guarantees"
  },
  {
    "objectID": "slides/intro.html#references",
    "href": "slides/intro.html#references",
    "title": "Amortized Bayesian Inference",
    "section": "References",
    "text": "References\n\n\n\n\nCranmer, K., Brehmer, J., & Louppe, G. (2020). The frontier of simulation-based inference. Proceedings of the National Academy of Sciences, 117(48), 30055–30062.\n\n\nSimon, H. A. (1983). Why should machines learn? In Machine learning (pp. 25–37). Elsevier.\n\n\nvan Rooij, I., Guest, O., Adolfi, F., Haan, R. de, Kolokolova, A., & Rich, P. (2024). Reclaiming AI as a theoretical tool for cognitive science. Computational Brain & Behavior, 7(4), 616–636."
  },
  {
    "objectID": "slides/deep-learning.html#section-1",
    "href": "slides/deep-learning.html#section-1",
    "title": "Deep Learning",
    "section": "",
    "text": "Shahab et al. (2024)"
  },
  {
    "objectID": "slides/deep-learning.html#python-frameworks",
    "href": "slides/deep-learning.html#python-frameworks",
    "title": "Deep Learning",
    "section": "Python frameworks",
    "text": "Python frameworks\n\nPyTorch\nTensorFlow\nJAX\nkeras"
  },
  {
    "objectID": "slides/deep-learning.html#pytorch",
    "href": "slides/deep-learning.html#pytorch",
    "title": "Deep Learning",
    "section": "PyTorch",
    "text": "PyTorch\n\ncreated by Meta (formerly Facebook)\neasy to learn\nfocus on research prototypes\nmodels are not compiled"
  },
  {
    "objectID": "slides/deep-learning.html#tensorflow",
    "href": "slides/deep-learning.html#tensorflow",
    "title": "Deep Learning",
    "section": "TensorFlow",
    "text": "TensorFlow\n\ncreated by Google\neasy to learn\nfocus on production\nmodels are compiled"
  },
  {
    "objectID": "slides/deep-learning.html#jax",
    "href": "slides/deep-learning.html#jax",
    "title": "Deep Learning",
    "section": "JAX",
    "text": "JAX\n\ncreated by Google\npure, functional approach\nJIT compiled\nfastest in runtime\nmost difficult to learn"
  },
  {
    "objectID": "slides/deep-learning.html#keras",
    "href": "slides/deep-learning.html#keras",
    "title": "Deep Learning",
    "section": "keras",
    "text": "keras\n\ncreated by Google\nAPI library\nUses PyTorch, TensorFlow, or jax as a backend\n\n\n\nPython\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # torch, jax\nimport keras"
  },
  {
    "objectID": "slides/deep-learning.html#keras-1",
    "href": "slides/deep-learning.html#keras-1",
    "title": "Deep Learning",
    "section": "keras",
    "text": "keras\n\ncreated by Google\nAPI library\nUses PyTorch, TensorFlow, or jax as a backend\n\n\n\nTerminal\n\nconda env config vars set KERAS_BACKEND=jax\n\n\n\n\nPython\n\nimport keras"
  },
  {
    "objectID": "slides/deep-learning.html#tensors",
    "href": "slides/deep-learning.html#tensors",
    "title": "Deep Learning",
    "section": "Tensors",
    "text": "Tensors\n\nAll of Deep Learning revolves around “Tensors”\nSimilar to arrays in numpy\nAdditional features:\n\nValues and gradients\nCan be stored on GPUs (optional)"
  },
  {
    "objectID": "slides/deep-learning.html#tensors-1",
    "href": "slides/deep-learning.html#tensors-1",
    "title": "Deep Learning",
    "section": "Tensors",
    "text": "Tensors\n\n\nPython\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras\n\nx = keras.ops.zeros((16, 2))\nx.shape # TensorShape([16, 2])\nx.device # device:CPU:0\n\n\nFirst axis almost always batch_size (think “sample size”)\nOther axes contextual (timepoint, feature, variable, row, column, etc)"
  },
  {
    "objectID": "slides/deep-learning.html#the-anatomy-of-neural-networks",
    "href": "slides/deep-learning.html#the-anatomy-of-neural-networks",
    "title": "Deep Learning",
    "section": "The anatomy of neural networks",
    "text": "The anatomy of neural networks"
  },
  {
    "objectID": "slides/deep-learning.html#neuron",
    "href": "slides/deep-learning.html#neuron",
    "title": "Deep Learning",
    "section": "Neuron",
    "text": "Neuron\nRegression + non-linear activation"
  },
  {
    "objectID": "slides/deep-learning.html#perceptron",
    "href": "slides/deep-learning.html#perceptron",
    "title": "Deep Learning",
    "section": "Perceptron",
    "text": "Perceptron\n\n\nMultiple regressions + non-linear activations\n\\[\n\\begin{aligned}\nz_k &= \\sigma \\Big(b_k + \\sum_{j=1}^J W_{jk}x_j\\Big)\\\\\nz &= \\sigma \\Big(b + x W'\\Big)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#perceptron-in-code",
    "href": "slides/deep-learning.html#perceptron-in-code",
    "title": "Deep Learning",
    "section": "Perceptron in code",
    "text": "Perceptron in code\n\n\nPython\n\nimport keras\n\nnetwork = keras.models.Sequential([\n    keras.Input((3,)),\n    keras.layers.Dense(5, activation=\"relu\"),\n])\nnetwork.summary()\n\nx = keras.random.normal((100, 3))\nx.shape # TensorShape([100, 3])\n\nz = network(x)\nz.shape # TensorShape([100, 5])"
  },
  {
    "objectID": "slides/deep-learning.html#multi-layer-perceptron",
    "href": "slides/deep-learning.html#multi-layer-perceptron",
    "title": "Deep Learning",
    "section": "Multi-Layer Perceptron",
    "text": "Multi-Layer Perceptron\nMultiple “layers” of perceptrons"
  },
  {
    "objectID": "slides/deep-learning.html#multi-layer-perceptron-1",
    "href": "slides/deep-learning.html#multi-layer-perceptron-1",
    "title": "Deep Learning",
    "section": "Multi-Layer Perceptron",
    "text": "Multi-Layer Perceptron\nFunction composition\n\\[\n\\begin{aligned}\nz & = f(x) \\text{ where } f = f_L \\circ f_{L-1} \\circ \\dots \\circ f_1 \\\\\nz & = f_L(\\dots(f_2(f_1(x)))) \\\\\n\\end{aligned}\n\\]\n\n\\(W_{jk}^l\\): weight of the input \\(j\\) to the output \\(k\\) in the layer \\(l\\)"
  },
  {
    "objectID": "slides/deep-learning.html#multi-layer-perceptron-in-code",
    "href": "slides/deep-learning.html#multi-layer-perceptron-in-code",
    "title": "Deep Learning",
    "section": "Multi-Layer Perceptron in Code",
    "text": "Multi-Layer Perceptron in Code\n\n\nPython\n\nimport keras\n\nnetwork = keras.models.Sequential([\n    keras.Input((3,)),\n    keras.layers.Dense(4, activation=\"relu\"),   # 3 inputs, 4 outputs\n    keras.layers.Dense(4, activation=\"relu\"),   # 4 inputs, 4 outputs\n    keras.layers.Dense(2, activation=\"softmax\") # 4 inputs, 2 outputs\n])\nnetwork.summary()\n\nx = keras.random.normal((100, 3))\nx.shape # TensorShape([100, 3])\n\nz = network(x)\nz.shape # TensorShape([100, 2])"
  },
  {
    "objectID": "slides/deep-learning.html#multi-layer-perceptron-in-code-1",
    "href": "slides/deep-learning.html#multi-layer-perceptron-in-code-1",
    "title": "Deep Learning",
    "section": "Multi-Layer Perceptron in Code",
    "text": "Multi-Layer Perceptron in Code\n\n\nPython\n\nimport keras\n\nnetwork = keras.models.Sequential([\n    keras.Input((3,)),\n    keras.layers.Dense(4, activation=\"relu\"),   # 3 inputs, 4 outputs\n    keras.layers.Dense(4, activation=\"relu\"),   # 4 inputs, 4 outputs\n    keras.layers.Dense(2, activation=\"softmax\") # 4 inputs, 2 outputs\n])\nnetwork.summary()\n\nx = keras.random.normal((100, 3))\nx.shape # TensorShape([100, 3])\n\nz = network(x) \nz.shape # TensorShape([100, 2])"
  },
  {
    "objectID": "slides/deep-learning.html#why-activation-functions",
    "href": "slides/deep-learning.html#why-activation-functions",
    "title": "Deep Learning",
    "section": "Why activation functions?",
    "text": "Why activation functions?\n\nA composition of linear functions is itself a linear function\nNon-linear activations introduces non-linearity\n\\(\\rightarrow\\) Represent any non-linear function\nOften used for output range control"
  },
  {
    "objectID": "slides/deep-learning.html#what-is-an-activation-function",
    "href": "slides/deep-learning.html#what-is-an-activation-function",
    "title": "Deep Learning",
    "section": "What is an activation function?",
    "text": "What is an activation function?\n\n\nBasic idea: Neuron “firing activity” based on its internal state\nRequirements:\n\nNon-linearity (expressiveness)\nDifferentiability (training)\nEfficiency (scalability)\n\nMany options (Kunc & Kléma, 2024)\n\nhttps://keras.io/api/layers/activations/"
  },
  {
    "objectID": "slides/deep-learning.html#activation-functions-1",
    "href": "slides/deep-learning.html#activation-functions-1",
    "title": "Deep Learning",
    "section": "Activation functions",
    "text": "Activation functions\n\\[\n\\tanh{(x)} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#activation-functions-2",
    "href": "slides/deep-learning.html#activation-functions-2",
    "title": "Deep Learning",
    "section": "Activation functions",
    "text": "Activation functions\n\\[\n\\text{ReLU}(x) = \\begin{cases} 0, x \\leq 0 \\\\ x, x &gt; 0\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#activation-functions-3",
    "href": "slides/deep-learning.html#activation-functions-3",
    "title": "Deep Learning",
    "section": "Activation functions",
    "text": "Activation functions\n\\[\n\\text{softplus}(x) = \\log(1 + e^x)\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#activation-functions-4",
    "href": "slides/deep-learning.html#activation-functions-4",
    "title": "Deep Learning",
    "section": "Activation functions",
    "text": "Activation functions\n\\[\n\\sigma(x) = \\frac{1}{1 + e^{-x}}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#activation-functions-5",
    "href": "slides/deep-learning.html#activation-functions-5",
    "title": "Deep Learning",
    "section": "Activation functions",
    "text": "Activation functions\n\\[\n\\text{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{J} e^{x_j}}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#training-networks-1",
    "href": "slides/deep-learning.html#training-networks-1",
    "title": "Deep Learning",
    "section": "Training networks",
    "text": "Training networks\n\nNetworks take an input and produce an output\nThe output depends on the weights and biases (parameters) of the neurons\nTraining: Adjusting the network parameters"
  },
  {
    "objectID": "slides/deep-learning.html#ingredients",
    "href": "slides/deep-learning.html#ingredients",
    "title": "Deep Learning",
    "section": "Ingredients",
    "text": "Ingredients\n\nNetwork\n\nWhat is the network architecture?\nWhat are the parameters of the network \\(\\theta\\)?\n\nData\n\nWhat information do we have available?\n\nGoal\n\nWhat do we want the network to do?"
  },
  {
    "objectID": "slides/deep-learning.html#loss-function",
    "href": "slides/deep-learning.html#loss-function",
    "title": "Deep Learning",
    "section": "Loss function",
    "text": "Loss function\n\nThe goal is operationalized by a loss function\n\n\\[\n\\mathcal{L}(x; \\theta)\n\\]\n\n\\(\\theta\\): Network parameters\n\\(x\\): Data"
  },
  {
    "objectID": "slides/deep-learning.html#training-networks-2",
    "href": "slides/deep-learning.html#training-networks-2",
    "title": "Deep Learning",
    "section": "Training networks",
    "text": "Training networks\nMinimise the loss with respect to the model parameters\n\\[\n\\operatorname*{argmin}_{\\theta} \\mathcal{L}(x; \\theta)\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#optimization",
    "href": "slides/deep-learning.html#optimization",
    "title": "Deep Learning",
    "section": "Optimization",
    "text": "Optimization\nSecond order derivatives\n\ne.g., Newton’s method\nFew slow steps\nSmall data\n\nFirst order derivatives\n\ne.g., Gradient descent\nMany cheap steps\nLarge data\n\nFunction values & heuristics\n\ne.g., Nelder-Mead, BFGS, Differential evolution, …"
  },
  {
    "objectID": "slides/deep-learning.html#gradient-descent-gd",
    "href": "slides/deep-learning.html#gradient-descent-gd",
    "title": "Deep Learning",
    "section": "Gradient descent (GD)",
    "text": "Gradient descent (GD)\n\\[\n\\theta_{n+1} = \\theta_n - \\gamma \\Delta_\\theta \\mathcal{L}(x; \\theta_n)\n\\]\n\n\\(\\theta_{n+1}\\): New network weights\n\\(\\theta_n\\): Current network weights\n\\(\\gamma\\): Learning rate\n\\(\\Delta_\\theta\\): Gradient (matrix of partial derivatives w.r.t network weights)\n\\(\\mathcal{L}\\): Loss function\n\\(x\\): Data"
  },
  {
    "objectID": "slides/deep-learning.html#stochastic-gradient-descent-sgd",
    "href": "slides/deep-learning.html#stochastic-gradient-descent-sgd",
    "title": "Deep Learning",
    "section": "Stochastic gradient descent (SGD)",
    "text": "Stochastic gradient descent (SGD)\nGD\n\nRun through all data to do a single step\n\nSGD\n\nMake a single step based on a subset of the data (minibatch)"
  },
  {
    "objectID": "slides/deep-learning.html#learning-rate-lr",
    "href": "slides/deep-learning.html#learning-rate-lr",
    "title": "Deep Learning",
    "section": "Learning rate (LR)",
    "text": "Learning rate (LR)\n\\[\n\\theta_{n+1} = \\theta_n - \\gamma \\Delta_\\theta \\mathcal{L}(x; \\theta_n)\n\\]\n\nToo small LR: Too many steps to converge\nToo large LR: May not converge"
  },
  {
    "objectID": "slides/deep-learning.html#adaptive-gradient",
    "href": "slides/deep-learning.html#adaptive-gradient",
    "title": "Deep Learning",
    "section": "Adaptive gradient",
    "text": "Adaptive gradient\n\nAdjust LR based on multiple iterations\nIndividual LR per parameter\n\n\\[\ng_n = \\Delta_\\theta \\mathcal{L}(x; \\theta_n)\n\\]\n\\[\nG_n = G_{n-1} + g_n^2\n\\]\n\\[\n\\theta_{n+1} = \\theta_n + \\frac{\\gamma}{\\sqrt{G_n} + \\epsilon} g_n\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#momentum",
    "href": "slides/deep-learning.html#momentum",
    "title": "Deep Learning",
    "section": "Momentum",
    "text": "Momentum\n\nAccumulate gradient over iterations\nSmoother parameter updates\nAvoid getting stuck in local minima, saddle points\n\n\\[\nm_n = \\beta m_{n-1} + (1-\\beta) \\Delta_\\theta \\mathcal{L}(x; \\theta_n)\n\\]\n\\[\n\\theta_{n+1} = \\theta_n - \\gamma m_n\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#adam-kingma2014adam",
    "href": "slides/deep-learning.html#adam-kingma2014adam",
    "title": "Deep Learning",
    "section": "Adam (Kingma & Ba, 2014)",
    "text": "Adam (Kingma & Ba, 2014)\n\\[\ng_n = \\Delta_\\theta \\mathcal{L}(x; \\theta_n)\n\\] \\[\n\\begin{aligned}\nm_n & = \\beta_1 m_{n-1} + (1-\\beta_1) g_n; & \\hat{m}_n & = \\frac{m_n}{1 - \\beta_1^n} \\\\\nv_n & = \\beta_2 v_{n-1} + (1-\\beta_2) g_n^2; & \\hat{v}_n & = \\frac{v_n}{1 - \\beta_1^n}\\\\\n\\end{aligned}\n\\]\n\\[\n\\theta_{n+1} = \\theta_n - \\frac{\\gamma}{\\sqrt{\\hat{v}_n} + \\epsilon} \\hat{m}_t\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#evaluating-gradients",
    "href": "slides/deep-learning.html#evaluating-gradients",
    "title": "Deep Learning",
    "section": "Evaluating gradients",
    "text": "Evaluating gradients\n\\[\\Delta_\\theta \\mathcal{L}(x; \\theta_n)\\]"
  },
  {
    "objectID": "slides/deep-learning.html#backpropagation",
    "href": "slides/deep-learning.html#backpropagation",
    "title": "Deep Learning",
    "section": "Backpropagation",
    "text": "Backpropagation\n\\[\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta_l} = \\frac{\\partial \\mathcal{L}}{\\partial z_L} \\frac{\\partial z_L}{\\partial z_{L-1}} \\dots \\frac{\\partial z_l}{\\partial \\theta_l}\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#kernel-trick",
    "href": "slides/deep-learning.html#kernel-trick",
    "title": "Deep Learning",
    "section": "Kernel trick",
    "text": "Kernel trick\n\nNon-linear patterns in the data\nProject data into a higher-dimensional space\n\n\nFigure by Gregory Gundersen\\(\\rightarrow\\) networks to add dimensions"
  },
  {
    "objectID": "slides/deep-learning.html#learning-rate-scheduling",
    "href": "slides/deep-learning.html#learning-rate-scheduling",
    "title": "Deep Learning",
    "section": "Learning rate scheduling",
    "text": "Learning rate scheduling\n\nChange LR through training\nTypically: Quick warm up to target, then decay to zero\nImproved convergence\n\n\n\n\nPython\n\nschedule = keras.optimizers.schedules.CosineDecay(\n  initial_learning_rate=1e-3\n)\noptimizer = keras.optimizers.Adam(learning_rate=schedule)"
  },
  {
    "objectID": "slides/deep-learning.html#issues-with-gradients",
    "href": "slides/deep-learning.html#issues-with-gradients",
    "title": "Deep Learning",
    "section": "Issues with gradients",
    "text": "Issues with gradients\nGradients can become excessively large or vanishingly small \n\n\nExploding gradients\n\nUnstable training (jumping erratically)\nNumerical issues (overflow)\n\nRemedies\n\nBatch normalization\nGradient clipping\n\n\nVanishing gradients\n\nSlow training (barely moving)\nNumerical issues (underflow)\n\nRemedies\n\nBatch normalization\nDifferent activation functions\nResidual connections"
  },
  {
    "objectID": "slides/deep-learning.html#batch-normalization",
    "href": "slides/deep-learning.html#batch-normalization",
    "title": "Deep Learning",
    "section": "Batch normalization",
    "text": "Batch normalization\n\nKeep output close to mean 0 and variance 1\n\n\n\nPython\n\nnetwork = keras.models.Sequential([\n    keras.Input((3,)),\n    keras.layers.Dense(4, activation=\"relu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(4),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Dense(2, activation=\"softmax\")\n])"
  },
  {
    "objectID": "slides/deep-learning.html#batch-normalization-1",
    "href": "slides/deep-learning.html#batch-normalization-1",
    "title": "Deep Learning",
    "section": "Batch normalization",
    "text": "Batch normalization\n\nKeep output close to mean 0 and variance 1\n\n\n\nPython\n\nnetwork = keras.models.Sequential([\n    keras.Input((3,)),\n    keras.layers.Dense(4, activation=\"relu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(4),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Dense(2, activation=\"softmax\")\n])"
  },
  {
    "objectID": "slides/deep-learning.html#gradient-clipping",
    "href": "slides/deep-learning.html#gradient-clipping",
    "title": "Deep Learning",
    "section": "Gradient clipping",
    "text": "Gradient clipping\nScale down gradients if they exceed certain threshold\n\n\n\nValue clipping\n\nRestrict gradients to a specified range\nEach gradient clipped individually\n\n\nNorm clipping\n\nRestrict the size (norm) of the gradient to a specified range\nAll gradients rescaled so that the norm becomes smaller\n\n\n\n\nPython\n\noptimizer=keras.optimizers.Adam(\n  learning_rate=1e-3, \n  clipvalue=0.5,\n  clipnorm=1.0)"
  },
  {
    "objectID": "slides/deep-learning.html#residual-skip-connections",
    "href": "slides/deep-learning.html#residual-skip-connections",
    "title": "Deep Learning",
    "section": "Residual / skip connections",
    "text": "Residual / skip connections\n\nAdd output of a layer with its input\nRemoves vanishing gradients\nLayer learns the “residual”: \\(f(x) = r(x) + x\\)\n\n\n\nPython\n\ninputs = keras.Input(shape=(64,))\n\nresidual = keras.layers.Dense(64)(inputs)\noutputs = keras.layers.Add()([residual, inputs])\noutputs = keras.layers.Activation(\"relu\")(outputs)\n\noutputs = keras.layers.Dense(10, activation=\"softmax\")(outputs)\n\nmodel = keras.Model(inputs, outputs)"
  },
  {
    "objectID": "slides/deep-learning.html#guards-against-overfiting",
    "href": "slides/deep-learning.html#guards-against-overfiting",
    "title": "Deep Learning",
    "section": "Guards against overfiting",
    "text": "Guards against overfiting\nLarge networks tend to overfit"
  },
  {
    "objectID": "slides/deep-learning.html#guards-against-overfiting-1",
    "href": "slides/deep-learning.html#guards-against-overfiting-1",
    "title": "Deep Learning",
    "section": "Guards against overfiting",
    "text": "Guards against overfiting\nLarge networks tend to overfit\n\nRemedies\n\nEarly stopping\nRegularization\nDropout\nAdd more data\n…"
  },
  {
    "objectID": "slides/deep-learning.html#early-stopping",
    "href": "slides/deep-learning.html#early-stopping",
    "title": "Deep Learning",
    "section": "Early stopping",
    "text": "Early stopping"
  },
  {
    "objectID": "slides/deep-learning.html#early-stopping-1",
    "href": "slides/deep-learning.html#early-stopping-1",
    "title": "Deep Learning",
    "section": "Early stopping",
    "text": "Early stopping\n\n\n\nPython\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    restore_best_weights=True \n)\n\nmodel.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=100,\n    callbacks=[early_stopping]\n)"
  },
  {
    "objectID": "slides/deep-learning.html#regularization",
    "href": "slides/deep-learning.html#regularization",
    "title": "Deep Learning",
    "section": "Regularization",
    "text": "Regularization\nAdd (weighted) norm of the parameters to the loss \\[\n\\mathcal{L}(x, \\theta) = \\mathcal{L}_0(x, \\theta) + \\lambda ||\\theta||\n\\]\n\n\nL1\n\n\\(||\\theta||_1 = \\sum|\\theta|\\)\nEncourages sparse weights\nDiscourages large weights\nFeature selection/pruning\n\n\nL2\n\n\\(||\\theta||_2 = \\sum\\theta^2\\)\nEncourages spread out weights\nDiscourages large weights"
  },
  {
    "objectID": "slides/deep-learning.html#regularization-1",
    "href": "slides/deep-learning.html#regularization-1",
    "title": "Deep Learning",
    "section": "Regularization",
    "text": "Regularization\n\n\nPython\n\nnetwork = keras.Sequential([\n    keras.layers.Dense(64, \n        activation=\"relu\", \n        kernel_regularizer=keras.regularizers.l1(0.01)),\n    keras.layers.Dense(32, \n        activation=\"relu\", \n        kernel_regularizer=keras.regularizers.l2(0.02)),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\n\n\nIn keras\n\nkernel_regularizer: Weights\nbias_regularizer: Bias\nactivity_regularizer: Layer output"
  },
  {
    "objectID": "slides/deep-learning.html#dropout",
    "href": "slides/deep-learning.html#dropout",
    "title": "Deep Learning",
    "section": "Dropout",
    "text": "Dropout\nDuring training, “turn off” each activation with a probability \\(p\\)\n\nImage source: learnopencv.com\nBetter generalization\nReduced dependence on single neurons\nReduced expressiveness\nIncreased variance during training"
  },
  {
    "objectID": "slides/deep-learning.html#dropout-1",
    "href": "slides/deep-learning.html#dropout-1",
    "title": "Deep Learning",
    "section": "Dropout",
    "text": "Dropout\n\n\nPython\n\nnetwork = keras.Sequential([\n    keras.Input((2,)),\n    keras.layers.Dense(64, activation=\"relu\"),\n    keras.layers.Dropout(0.1),\n    keras.layers.Dense(64, activation=\"relu\"),\n    keras.layers.Dropout(0.05),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\n\nx = keras.random.normal((100, 2))\n\nnetwork(x)\nnetwork(x, training=True)"
  },
  {
    "objectID": "slides/deep-learning.html#dropout-2",
    "href": "slides/deep-learning.html#dropout-2",
    "title": "Deep Learning",
    "section": "Dropout",
    "text": "Dropout\n\n\nPython\n\nnetwork = keras.Sequential([\n    keras.Input((2,)),\n    keras.layers.Dense(64, activation=\"relu\"),\n    keras.layers.Dropout(0.1),\n    keras.layers.Dense(64, activation=\"relu\"),\n    keras.layers.Dropout(0.05),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\n\nx = keras.random.normal((100, 2))\n\nnetwork(x)\nnetwork(x, training=True)"
  },
  {
    "objectID": "slides/deep-learning.html#mlp",
    "href": "slides/deep-learning.html#mlp",
    "title": "Deep Learning",
    "section": "MLP",
    "text": "MLP\nPros\n\nConceptually simple, universal function approximator\nEasy to train, established\nAlmost zero assumptions about data\n\nCons\n\nInefficient in high dimensions (many parameters)\nWorks only with fixed size input/output\nAlmost zero assumptions about data"
  },
  {
    "objectID": "slides/deep-learning.html#assumptions-data-types",
    "href": "slides/deep-learning.html#assumptions-data-types",
    "title": "Deep Learning",
    "section": "Assumptions: Data types",
    "text": "Assumptions: Data types\nExamples:\n\nPictures\nSequences (text, time-series)\nSets\n\n\\(\\rightarrow\\) leverage properties of data to our advantage by building networks that make correct assumptions"
  },
  {
    "objectID": "slides/deep-learning.html#recurrent-neural-network-rnn",
    "href": "slides/deep-learning.html#recurrent-neural-network-rnn",
    "title": "Deep Learning",
    "section": "Recurrent neural network (RNN)",
    "text": "Recurrent neural network (RNN)\n\nWorks for sequences of different lengths\nMaintain a hidden state \\(h_t = \\sigma_h(W_h * h_{t-1} + W_x x_t + b_h)\\)\nOutput depends on hidden state \\(y_t = \\sigma_y(W_g * h_t + b_y)\\)\n\n\n\n\nIssues\n\nSequential updating\nLimited long-term memory\nVanishing gradient\n\n\n\n\n\nSource: Christopher Olah’s blog"
  },
  {
    "objectID": "slides/deep-learning.html#long-short-term-memory-lstm",
    "href": "slides/deep-learning.html#long-short-term-memory-lstm",
    "title": "Deep Learning",
    "section": "Long short-term memory (LSTM)",
    "text": "Long short-term memory (LSTM)\n\nLearn to what to “forget” (forget gate) and what to “remember” (input gate)\nCell state can carry over long term dependencies\n\n\nSource: Christopher Olah’s blog"
  },
  {
    "objectID": "slides/deep-learning.html#attention-vaswani2017attention",
    "href": "slides/deep-learning.html#attention-vaswani2017attention",
    "title": "Deep Learning",
    "section": "Attention (Vaswani et al., 2017)",
    "text": "Attention (Vaswani et al., 2017)\n\nSequential updating is slow\nLimited memory (even for LSTM)\n\nSolution\n\nUse positional encoding (“concatenate with time variable”)\nParalellize the whole computation\n“Attention”: Focus on the relevant parts of the sentence."
  },
  {
    "objectID": "slides/deep-learning.html#attention",
    "href": "slides/deep-learning.html#attention",
    "title": "Deep Learning",
    "section": "Attention",
    "text": "Attention\n\nQuery: \\(Q = XW_Q\\)\nKey: \\(K=XW_K\\)\nValue: \\(V=XW_V\\)\n\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}(QK^{\\text{T}})V\n\\]"
  },
  {
    "objectID": "slides/deep-learning.html#attention-1",
    "href": "slides/deep-learning.html#attention-1",
    "title": "Deep Learning",
    "section": "Attention",
    "text": "Attention"
  },
  {
    "objectID": "slides/deep-learning.html#attention-2",
    "href": "slides/deep-learning.html#attention-2",
    "title": "Deep Learning",
    "section": "Attention",
    "text": "Attention"
  },
  {
    "objectID": "slides/deep-learning.html#attention-3",
    "href": "slides/deep-learning.html#attention-3",
    "title": "Deep Learning",
    "section": "Attention",
    "text": "Attention\n\nCross-attention\n\nKeys and queries are computed from different sources\ne.g., original (keys) and translated (queries) text\n\nMultihead attention\n\nMultiple attention blocks in parallel\nEach block “attends” to different representations\n\nTransformers: Multiple layers of Multihead attention layers and MLP"
  },
  {
    "objectID": "slides/deep-learning.html#set-architectures",
    "href": "slides/deep-learning.html#set-architectures",
    "title": "Deep Learning",
    "section": "Set architectures",
    "text": "Set architectures\n\nWhat if we do not have a fixed order?\nInstead, we have sets"
  },
  {
    "objectID": "slides/deep-learning.html#set-architectures-1",
    "href": "slides/deep-learning.html#set-architectures-1",
    "title": "Deep Learning",
    "section": "Set architectures",
    "text": "Set architectures\n\nPermutation invariant function: \\(f(x) = f(\\pi(x))\\)\nEmbeddings of sets\n\nHandle different set sizes\nPermutation invariant\nInteractions between elements"
  },
  {
    "objectID": "slides/deep-learning.html#deep-set-zaheer_deep_2017",
    "href": "slides/deep-learning.html#deep-set-zaheer_deep_2017",
    "title": "Deep Learning",
    "section": "Deep Set (Zaheer et al., 2017)",
    "text": "Deep Set (Zaheer et al., 2017)\n\n\n\\[\nf(X = \\{ x_i \\}) = \\rho \\left( \\sigma(\\tau(X)) \\right)\n\\]\n\n\\(\\tau\\): Permutation equivariant function\n\\(\\sigma\\): Permutation invariant pooling function (sum, mean)\n\\(\\rho\\): Any function"
  },
  {
    "objectID": "slides/deep-learning.html#deep-set",
    "href": "slides/deep-learning.html#deep-set",
    "title": "Deep Learning",
    "section": "Deep Set",
    "text": "Deep Set"
  },
  {
    "objectID": "slides/deep-learning.html#examples-further-references",
    "href": "slides/deep-learning.html#examples-further-references",
    "title": "Deep Learning",
    "section": "Examples & further references",
    "text": "Examples & further references\n\nKeras code examples\nTensorflow playground\nChollet (2021), GitHub\nUrban & Gates (2021)"
  },
  {
    "objectID": "slides/deep-learning.html#references",
    "href": "slides/deep-learning.html#references",
    "title": "Deep Learning",
    "section": "References",
    "text": "References\n\n\n\n\nChollet, F. (2021). Deep learning with Python. Manning Publications.\n\n\nKingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv Preprint arXiv:1412.6980.\n\n\nKunc, V., & Kléma, J. (2024). Three decades of activations: A comprehensive survey of 400 activation functions for neural networks. arXiv Preprint arXiv:2402.09092.\n\n\nShahab, O., El Kurdi, B., Shaukat, A., Nadkarni, G., & Soroush, A. (2024). Large language models: A primer and gastroenterology applications. Therapeutic Advances in Gastroenterology, 17, 17562848241227031.\n\n\nUrban, C. J., & Gates, K. M. (2021). Deep learning: A primer for psychologists. Psychological Methods, 26(6), 743.\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing Systems, 30.\n\n\nZaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R., & Smola, A. J. (2017). Deep Sets. Advances in Neural Information Processing Systems, 30."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the seminar!",
    "section": "",
    "text": "You can use this website to access materials related to the workshop."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Welcome to the seminar!",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay\nTime\nTopic\n\n\n\n\nWed\n9:00-10:30\nIntroduction, Deep Learning\n\n\nWed\n11:00-12:30\nDeep Learning, Generative Neural Networks\n\n\nWed\n14:00-15:30\nPractical exercise\n\n\nWed\n16:00-17:30\nAmortized Bayesian Inference with BayesFlow\n\n\nThu\n9:00-10:30\nBayesFlow demonstration\n\n\nThu\n11:00-12:30\nPractical exercise"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Welcome to the seminar!",
    "section": "Slides",
    "text": "Slides\nHere you can access the presentation slides\n\nIntroduction\nDeep Learning\nGenerative Neural Networks\nAmortized Bayesian Inference with BayesFlow"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Welcome to the seminar!",
    "section": "Exercises",
    "text": "Exercises\nUse the Exercises tab in the navigation bar to access exercise notebooks."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Welcome to the seminar!",
    "section": "Projects",
    "text": "Projects\nUse the Projects tab in the navigation bar to access the project descriptions. See https://quantitative-thinking.eu/mobilities/seminar-2025/ for all projects."
  },
  {
    "objectID": "index.html#environment",
    "href": "index.html#environment",
    "title": "Welcome to the seminar!",
    "section": "Environment",
    "text": "Environment\nThe exercises and projects require Python 3.10 – 3.12, and installing necessary libraries. The recommended steps using conda:\n\n\nTerminal\n\n# create a \"bayesflow-seminar\" conda environment with Python 3.11\nconda create --name bayesflow-seminar python=3.11.11\n\n# activate the environment\nconda activate bayesflow-seminar\n\n# kernel for running the jupyter notebooks\nconda install ipykernel --update-deps --force-reinstall\n\n# install packages\npip install tensorflow\npip install git+https://github.com/bayesflow-org/bayesflow@main\n\nWhen running the exercise notebooks, remember to use the correct environment!\nNote: bayesflow can run with jax or pytorch instead of tensorflow. If you prefer to use those as a backend, you can install them as well. Remember to set the correct environment before loading keras, e.g., os.environ[\"KERAS_BACKEND\"] = \"jax\". Note that the examples of generative neural networks do require tensorflow regardless."
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Here you can download example notebooks related to creating your own generative neural network architectures.\n\n\n\nPeek online: here\nDownload notebook: here\n\nIn this exercise, you will build a normalizing flow based on affine coupling from scratch using keras, that will learn to transform the moons distribution into a standard normal.\n\n\n\n\n\n\n\nVideo\nForward direction\n\n\n\n\n\n\nVideo\nBackward direction\n\n\n\n\n\n\nFigure 1: Normalizing flow\n\n\n\n\n\n\n\nPeek online: here.\nDownload notebook: here.\nDownload data: here\n\nIn this exercise, you will build a flow matching model using keras that transports a standard normal distribution into a distribution based on the datasaurus.\n\n\n\nVideo\n\n\nFigure 2: Flow matching\n\n\n\n\n\n\n\nPeek online: here.\nDownload notebook: here.\n\nIn this exercise, you will expand the flow matching model so that you can condition the distribution on contextual variables. This will enable you to learn a flow that transports a doghnut distribution into the swiss roll distribution, mirrored along horizontal and vertical axes, depending on the context.\n\n\n\n\n\n\nFigure 3: Swiss roll mirrored along vertical or horizontal axes"
  },
  {
    "objectID": "exercises.html#generative-neural-networks",
    "href": "exercises.html#generative-neural-networks",
    "title": "Exercises",
    "section": "",
    "text": "Here you can download example notebooks related to creating your own generative neural network architectures.\n\n\n\nPeek online: here\nDownload notebook: here\n\nIn this exercise, you will build a normalizing flow based on affine coupling from scratch using keras, that will learn to transform the moons distribution into a standard normal.\n\n\n\n\n\n\n\nVideo\nForward direction\n\n\n\n\n\n\nVideo\nBackward direction\n\n\n\n\n\n\nFigure 1: Normalizing flow\n\n\n\n\n\n\n\nPeek online: here.\nDownload notebook: here.\nDownload data: here\n\nIn this exercise, you will build a flow matching model using keras that transports a standard normal distribution into a distribution based on the datasaurus.\n\n\n\nVideo\n\n\nFigure 2: Flow matching\n\n\n\n\n\n\n\nPeek online: here.\nDownload notebook: here.\n\nIn this exercise, you will expand the flow matching model so that you can condition the distribution on contextual variables. This will enable you to learn a flow that transports a doghnut distribution into the swiss roll distribution, mirrored along horizontal and vertical axes, depending on the context.\n\n\n\n\n\n\nFigure 3: Swiss roll mirrored along vertical or horizontal axes"
  },
  {
    "objectID": "exercises.html#bayesflow",
    "href": "exercises.html#bayesflow",
    "title": "Exercises",
    "section": "BayesFlow",
    "text": "BayesFlow\nPlease visit the BayesFlow repository to find a bunch of examples that can help you with BayesFlow. In addition, below are two exercise notebooks you can use to familiarize yourself with BayesFlow.\n\nEstimating the mean and variance of a gaussian variable\n\nPeek online: here.\nDownload notebook: here.\n\nThis notebook provides you with the very basics of the BayesFlow workflow - starting with defining simulators, through defining and training the neural approximators, and ending with network validation and inference.\n\n\nDiffusion decision model\n\nPeek online: here\nDownload notebook: here\nDownload data: here\n\nThis notebook provides you with a basic application of BayesFlow in the context of models of decision making - the Wald model of simple response times, and the racing diffusion model."
  },
  {
    "objectID": "slides/amortized-inference.html#recap",
    "href": "slides/amortized-inference.html#recap",
    "title": "Amortized Bayesian Inference",
    "section": "Recap",
    "text": "Recap\nProblem\nWe want to approximate \\(p(\\theta \\mid x)\\) or \\(p(x \\mid \\theta)\\)\n\\[\np(\\theta \\mid x) = \\frac{p(\\theta) \\times p(x \\mid \\theta)}{p(x)}\n\\]\n\nEvaluating \\(p(\\theta)\\), \\(p(x \\mid \\theta)\\) and \\(p(x)\\) may not be tractable\nBut we are able to sample \\((x^{(s)}, \\theta^{(s)}) \\sim p(x, \\theta)\\)\n\nSolution\nUse generative neural networks"
  },
  {
    "objectID": "slides/amortized-inference.html#inference-network",
    "href": "slides/amortized-inference.html#inference-network",
    "title": "Amortized Bayesian Inference",
    "section": "Inference network",
    "text": "Inference network\n\nA generative neural network \\(q_\\phi(\\theta \\mid x)\\)\n\nNormalizing flow, flow matching, …\nModel the distribution of parameters, conditioned on data\n\n\nGoal:\n\\[p(\\theta \\mid x) \\approx q_\\phi(\\theta \\mid x)\\]"
  },
  {
    "objectID": "slides/amortized-inference.html#role-of-data",
    "href": "slides/amortized-inference.html#role-of-data",
    "title": "Amortized Bayesian Inference",
    "section": "Role of “data”",
    "text": "Role of “data”\n\n\\(x\\) conditions the generative network\n\nNormalizing flows: Input to coupling network (usually MLP)\nFlow matching: Input to the vector field network (usually MLP)\n\n\n\\(\\rightarrow\\) Must be of fixed dimensions"
  },
  {
    "objectID": "slides/amortized-inference.html#data-of-varying-dimensions",
    "href": "slides/amortized-inference.html#data-of-varying-dimensions",
    "title": "Amortized Bayesian Inference",
    "section": "Data of varying dimensions",
    "text": "Data of varying dimensions\n\nSample sizes, study design, resolution, …\n\n\\(\\rightarrow\\) Summary statistics\n\nHandcrafted: Mean, SD, Correlation,…\nSummary networks"
  },
  {
    "objectID": "slides/amortized-inference.html#summary-network-h_psi",
    "href": "slides/amortized-inference.html#summary-network-h_psi",
    "title": "Amortized Bayesian Inference",
    "section": "Summary network \\(h_\\psi\\)",
    "text": "Summary network \\(h_\\psi\\)\n\nTakes input of variable size\nOutputs fixed size embedding\n\n\n\\(\\rightarrow\\) Condition the inference network on the output of the summary network\n\\[p(\\theta \\mid x) \\approx q_\\phi(\\theta \\mid h_\\psi(x))\\]"
  },
  {
    "objectID": "slides/amortized-inference.html#learning-the-posterior",
    "href": "slides/amortized-inference.html#learning-the-posterior",
    "title": "Amortized Bayesian Inference",
    "section": "Learning the posterior",
    "text": "Learning the posterior\n\\[\n\\begin{aligned}\n\\hat{\\phi}, \\hat{\\psi} = \\operatorname*{argmin}_{\\phi, \\psi} & \\mathbb{E}_{x \\sim p(x)} \\mathbb{KL}\\big[p(\\theta \\mid x) || q_\\phi(\\theta \\mid h_\\psi(x))\\big] = \\\\\n= \\operatorname*{argmin}_{\\phi, \\psi} & \\mathbb{E}_{x \\sim p(x)} \\mathbb{E}_{\\theta \\sim p(\\theta \\mid x)} \\log \\frac{p(\\theta \\mid x)}{q_\\phi(\\theta \\mid h_\\psi(x))} \\propto \\\\\n\\propto \\operatorname*{argmin}_{\\phi, \\psi} & - \\mathbb{E}_{(x, \\theta) \\sim p(x, \\theta)} q_\\phi(\\theta \\mid h_\\psi(x)) \\approx\\\\\n\\approx \\operatorname*{argmin}_{\\phi, \\psi} & - \\frac{1}{S}\\sum_{s=1}^S \\log q_\\phi(\\theta^{(s)} \\mid h_\\psi(x^{(s)}))\n\\end{aligned}\n\\]\n\\(\\rightarrow\\) must be able to generate samples \\((x^{(s)}, \\theta^{(s)}) \\sim p(x, \\theta)\\)"
  },
  {
    "objectID": "slides/amortized-inference.html#training-the-networks",
    "href": "slides/amortized-inference.html#training-the-networks",
    "title": "Amortized Bayesian Inference",
    "section": "Training the networks",
    "text": "Training the networks\n\nDefine a generative statistical model\n\n\\(p(x, \\theta)\\), typically \\(p(\\theta) \\times p(x \\mid \\theta)\\)\n\nDefine inference and (optional) summary networks\n\n\\(q_\\phi(x \\mid h_\\psi(x))\\)\n\nTrain the networks\n\nSample from \\((x^{(s)}, \\theta^{(s)}) \\sim p(x, \\theta)\\)\nOptimize weights \\(\\phi\\) and \\(\\psi\\) so that \\(p(\\theta \\mid x) \\approx q_\\phi(\\theta \\mid h_\\psi(x))\\)"
  },
  {
    "objectID": "slides/amortized-inference.html#inference",
    "href": "slides/amortized-inference.html#inference",
    "title": "Amortized Bayesian Inference",
    "section": "Inference",
    "text": "Inference\n\nOnce the networks are trained, they can be used for inference\nMost of computational resources are used during training\nInference is fast (only requires a simple pass through the network)\n\n\\(\\rightarrow\\) Amortized inference: Pay upfront the cost of inference during training, making subsequent inference effective"
  },
  {
    "objectID": "slides/amortized-inference.html#amortized-bayesian-inference",
    "href": "slides/amortized-inference.html#amortized-bayesian-inference",
    "title": "Amortized Bayesian Inference",
    "section": "Amortized Bayesian Inference",
    "text": "Amortized Bayesian Inference\n \nFor more info, see Radev et al. (2020)"
  },
  {
    "objectID": "slides/amortized-inference.html#bayesflow-radev2023bayesflow",
    "href": "slides/amortized-inference.html#bayesflow-radev2023bayesflow",
    "title": "Amortized Bayesian Inference",
    "section": "BayesFlow (Radev, Schmitt, Schumacher, et al., 2023)",
    "text": "BayesFlow (Radev, Schmitt, Schumacher, et al., 2023)\n\nPython library\nImplementation of common neural architectures to make ABI easier\nHelper functions for simulation, configuration, training, validation, diagnostics,…"
  },
  {
    "objectID": "slides/amortized-inference.html#old-version",
    "href": "slides/amortized-inference.html#old-version",
    "title": "Amortized Bayesian Inference",
    "section": "Old version",
    "text": "Old version\n\nBuild on TensorFlow\nPrevious projects build with it\nBespoke syntax, not that transparent\nStale development (no new features), being deprecated\nstable legacy branch on GitHub\npip install git+https://github.com/bayesflow-org/bayesflow@stable-legacy"
  },
  {
    "objectID": "slides/amortized-inference.html#new-version",
    "href": "slides/amortized-inference.html#new-version",
    "title": "Amortized Bayesian Inference",
    "section": "New version",
    "text": "New version\n\nBuilt on keras\n\nTensorFlow, JAX, or PyTorch as a backend\n\nModern interface, more transparent, faster\nReleased very recently\nActive development, future standard\nmain branch on GitHub\npip install git+https://github.com/bayesflow-org/bayesflow@main"
  },
  {
    "objectID": "slides/amortized-inference.html#general-workflow",
    "href": "slides/amortized-inference.html#general-workflow",
    "title": "Amortized Bayesian Inference",
    "section": "General workflow",
    "text": "General workflow"
  },
  {
    "objectID": "slides/amortized-inference.html#ingredients",
    "href": "slides/amortized-inference.html#ingredients",
    "title": "Amortized Bayesian Inference",
    "section": "Ingredients",
    "text": "Ingredients\n\nSimulator\n\nSimulate data from the statistical model\n\nAdapter\n\nConfigure the data\n\nSummary network (optional)\n\nGet summary embeddings\n\nInference network\n\nApproximate the posterior"
  },
  {
    "objectID": "slides/amortized-inference.html#quality-of-life",
    "href": "slides/amortized-inference.html#quality-of-life",
    "title": "Amortized Bayesian Inference",
    "section": "Quality of life",
    "text": "Quality of life\n\nDiagnostics\n\nPlots and statistics to evaluate the approximation\n\nApproximator\n\nHold ingredients necessary for approximation together\nAdapter, Summary network, Inference network\n\nWorkflow\n\nHold ingredients for the entire pipeline together\nSimulator, Adapter, Summary network Inference network, Diagnostics"
  },
  {
    "objectID": "slides/amortized-inference.html#general-pipeline",
    "href": "slides/amortized-inference.html#general-pipeline",
    "title": "Amortized Bayesian Inference",
    "section": "General pipeline",
    "text": "General pipeline\n\nDefine the statistical model (through simulator)\nDefine the approximator (through neural networks)\nTrain the neural networks\nValidate the approximator\nInference and diagnostics"
  },
  {
    "objectID": "slides/amortized-inference.html#define-the-simulator",
    "href": "slides/amortized-inference.html#define-the-simulator",
    "title": "Amortized Bayesian Inference",
    "section": "Define the simulator",
    "text": "Define the simulator\n\nDefine the “statistical” model in terms of a simulator\nbayesflow expects “batched” simulations\n\n\n\nPython\n\nclass Simulator(bf.simulators.Simulator):\n    def sample(self, batch_size):\n        theta = np.random.beta(1, 1, size=batch_size)\n        x = np.random.binomial(n=10, p=theta)\n        return dict(theta=theta, x=x)\n\nsimulator = Simulator()\ndataset = simulator.sample(100)"
  },
  {
    "objectID": "slides/amortized-inference.html#define-the-simulator-1",
    "href": "slides/amortized-inference.html#define-the-simulator-1",
    "title": "Amortized Bayesian Inference",
    "section": "Define the simulator",
    "text": "Define the simulator\n\nDefine the “statistical” model in terms of a simulator\nbayesflow expects “batched” simulations\nmake_simulator: Convenient interface for “auto batching”\n\n\n\nPython\n\ndef prior():\n    return dict(mu = np.random.normal(0, 1))\n\ndef likelihood(mu):\n    return dict(x = np.random.normal(mu, 1, size=20))\n\nsimulator = bf.make_simulator([prior, likelihood])\n\nsimulator.sample(10)"
  },
  {
    "objectID": "slides/amortized-inference.html#simulator-data-of-varying-size",
    "href": "slides/amortized-inference.html#simulator-data-of-varying-size",
    "title": "Amortized Bayesian Inference",
    "section": "Simulator: Data of varying size",
    "text": "Simulator: Data of varying size\n\nThe shape of data must be the same within each batch\n\nStrategies:\n\nPad vectors to be the same length\nVary data shapes between batches"
  },
  {
    "objectID": "slides/amortized-inference.html#padmask-vectors",
    "href": "slides/amortized-inference.html#padmask-vectors",
    "title": "Amortized Bayesian Inference",
    "section": "Pad/mask vectors",
    "text": "Pad/mask vectors\n\n\nPython\n\ndef context():\n    return dict(n = np.random.randint(10, 101))\n\ndef prior():\n    return dict(mu = np.random.normal(0, 1))\n\ndef likelihood(mu, n):\n    observed = np.zeros(0)\n    observed[:n] = 1\n\n    x = np.zeros(100)\n    x[:n] = np.random.normal(mu, 1, size=n)\n    return dict(observed=observed, x=x)\n\nsimulator = bf.make_simulator([context, prior, likelihood])\n\nsimulator.sample(10)"
  },
  {
    "objectID": "slides/amortized-inference.html#vary-data-shape-between-batches",
    "href": "slides/amortized-inference.html#vary-data-shape-between-batches",
    "title": "Amortized Bayesian Inference",
    "section": "Vary data shape between batches",
    "text": "Vary data shape between batches\n\n\nPython\n\ndef context(batch_size):\n    return dict(n = np.random.randint(10, 101))\n\ndef prior():\n    return dict(mu = np.random.normal(0, 1))\n\ndef likelihood(mu, n):\n    x = np.random.normal(mu, 1, size=n)\n    return dict(x=x)\n\nsimulator = bf.make_simulator([prior, likelihood], meta_fn=context)\n\nsimulator.sample(10)"
  },
  {
    "objectID": "slides/amortized-inference.html#padding-vs-batched-context",
    "href": "slides/amortized-inference.html#padding-vs-batched-context",
    "title": "Amortized Bayesian Inference",
    "section": "Padding vs batched context",
    "text": "Padding vs batched context\n\nBoth approaches work\nBatched context is a bit cleaner\n\nDo not have to fiddle with masking\nLimited useability (cannot effectivelly use in offline mode)\n\nPadding\n\nMore verbose\nMore general"
  },
  {
    "objectID": "slides/amortized-inference.html#approximator",
    "href": "slides/amortized-inference.html#approximator",
    "title": "Amortized Bayesian Inference",
    "section": "Approximator",
    "text": "Approximator\n\nInference network\n\nGenerates distributions\n\n(Optional) summary network\n\nGenerates summary embeddings\n\nAdapter\n\nReshapes data to be passed into networks"
  },
  {
    "objectID": "slides/amortized-inference.html#inference-network-1",
    "href": "slides/amortized-inference.html#inference-network-1",
    "title": "Amortized Bayesian Inference",
    "section": "Inference network",
    "text": "Inference network\n\n\nPython\n\ninference_network = bf.networks.CouplingFlow()\n\n\n\n\nPython\n\ninference_network = bf.networks.FlowMatching()\n\n\nVarious options available, see the Two Moons Example."
  },
  {
    "objectID": "slides/amortized-inference.html#what-architecture-to-pick",
    "href": "slides/amortized-inference.html#what-architecture-to-pick",
    "title": "Amortized Bayesian Inference",
    "section": "What architecture to pick?",
    "text": "What architecture to pick?\n\n\n\nCoupling flow\n\nSlow training\nLess expressive\nFaster during inference\n\n\nFlow matching\n\nFast training\nMore expressive\nSlow inference on CPU"
  },
  {
    "objectID": "slides/amortized-inference.html#what-architecture-to-pick-1",
    "href": "slides/amortized-inference.html#what-architecture-to-pick-1",
    "title": "Amortized Bayesian Inference",
    "section": "What architecture to pick?",
    "text": "What architecture to pick?\n\nAffine coupling for low-dimensional, uni-modal posteriors\nSpline coupling for harder posteriors, including multi-modal\nFlow matching for highly complex posteriors\n\nor when inference speed is not of concern\nor if GPUs available"
  },
  {
    "objectID": "slides/amortized-inference.html#summary-network",
    "href": "slides/amortized-inference.html#summary-network",
    "title": "Amortized Bayesian Inference",
    "section": "Summary network",
    "text": "Summary network\n\nExtract all relevant information from the variable-sized data\nOutput fixed sized embeddings\n“Sufficient statistics”\nRule of thumb: output size should be at least \\(2\\times\\) the number of parameters"
  },
  {
    "objectID": "slides/amortized-inference.html#what-architecture-to-pick-2",
    "href": "slides/amortized-inference.html#what-architecture-to-pick-2",
    "title": "Amortized Bayesian Inference",
    "section": "What architecture to pick?",
    "text": "What architecture to pick?\nReflect symmetries in the data\nExchangeable data\n\nDeep Sets, Set Transformers,…\n\n\n\nPython\n\nsummary_network = bf.networks.DeepSet()\n\nTime series, Sequences, …\n\nRNNs, CNNs, Transformers, …\n\n\n\nPython\n\nsummary_network = bf.networks.LSTNet()"
  },
  {
    "objectID": "slides/amortized-inference.html#adapter-main-purpose",
    "href": "slides/amortized-inference.html#adapter-main-purpose",
    "title": "Amortized Bayesian Inference",
    "section": "Adapter: Main purpose",
    "text": "Adapter: Main purpose\n\nReshapes data to be passed into networks\nA hub that handles what is passed into what network\n\nMain keywords:\n\n\"inference_variables\": What are the variables that the inference network should learn about?\n\n\\(q(\\theta \\mid x) \\rightarrow\\) parameters \\(\\theta\\)\n\n\"inference_conditions\": What are the variables that the inference network should be directly conditioned on?\n\n\\(q(\\theta \\mid x) \\rightarrow\\) data \\(x\\)\n\n\"summary_variables\": What are the variables that are supposed to be passed into the summary network?\n\n\\(q(\\theta \\mid f(x)) \\rightarrow\\) data \\(x\\)"
  },
  {
    "objectID": "slides/amortized-inference.html#adapter",
    "href": "slides/amortized-inference.html#adapter",
    "title": "Amortized Bayesian Inference",
    "section": "Adapter",
    "text": "Adapter\n\n\nPython\n\nadapter = (bf.Adapter()\n  .concatenate([\"mu\", \"sigma\"], into = \"inference_variables\")\n  .rename([\"n\"], \"inference_conditions\")\n  .concatenate([\"x\", \"observed\"], into = \"summary_variables\")\n)\n\n\nTransform variables\n\n.standardize\n.sqrt, .log\n.constrain\n\nReshape variables\n\n.as_set, .as_time_series\n.broadcast\n.one_hot\n\n… and many more operations"
  },
  {
    "objectID": "slides/amortized-inference.html#approximator-1",
    "href": "slides/amortized-inference.html#approximator-1",
    "title": "Amortized Bayesian Inference",
    "section": "Approximator",
    "text": "Approximator\n\nHolds ingredients used for inference\n\n\n\nPython\n\napproximator = bf.approximators.ContinuousApproximator(\n    inference_network=inference_network,\n    summary_network=summary_network\n    adapter=adapter\n)"
  },
  {
    "objectID": "slides/amortized-inference.html#workflow-optional",
    "href": "slides/amortized-inference.html#workflow-optional",
    "title": "Amortized Bayesian Inference",
    "section": "Workflow (optional)",
    "text": "Workflow (optional)\n\nHold all ingredients used for training, inference, and diagnostics\n\n\n\nPython\n\nworkflow = bf.BasicWorkflow(\n    inference_network=inference_network,\n    summary_network=summary_network\n    adapter=adapter,\n    simulator=simulator\n)"
  },
  {
    "objectID": "slides/amortized-inference.html#network-training",
    "href": "slides/amortized-inference.html#network-training",
    "title": "Amortized Bayesian Inference",
    "section": "Network training",
    "text": "Network training\n\nIn principle, training as any other model in keras\n\napproximator.fit\n\nDefine optimizer (e.g., keras.optimizers.Adam)\n\n(optional) define schedule, early stopping,…\n\nDefine training budget and regime\n\nNumber of epochs\nBatch size, Number of batches\nSimulate data or supply simulator\n\nCompile and train the model until convergence\nBasicWorkflow makes fitting easier, comes with some predefined reasonable settings\n\ne.g. workflow.fit_online"
  },
  {
    "objectID": "slides/amortized-inference.html#training-regimes",
    "href": "slides/amortized-inference.html#training-regimes",
    "title": "Amortized Bayesian Inference",
    "section": "Training regimes",
    "text": "Training regimes\n\n\nOnline\n\nGenerate data during training\nSlower to train\nPrevents overfitting\n\n\nOffline\n\nTrain on fixed data\nFaster to train\nRisk of overfitting\n\n\nFrom disk\n\nOffline training\nLarge data that does not fit into memory\nRead data on demand during training"
  },
  {
    "objectID": "slides/amortized-inference.html#goals",
    "href": "slides/amortized-inference.html#goals",
    "title": "Amortized Bayesian Inference",
    "section": "Goals",
    "text": "Goals\n\nIs the neural approximator doing a good job at approximating the true posterior?\n\n“Computational faithfulness”\nAssesses the quality of approximator\n\nHow much can we expect to learn given data?\n\nParameter recovery, posterior contraction, posterior z-score\nAssesses how the statistical model interacts with data\n\n\nFor general discussion, see Schad et al. (2021)."
  },
  {
    "objectID": "slides/amortized-inference.html#procedure",
    "href": "slides/amortized-inference.html#procedure",
    "title": "Amortized Bayesian Inference",
    "section": "Procedure",
    "text": "Procedure\n\nDraw fresh validation data from the simulator\nExtract the parameter samples from the prior\nSample from the posterior\n\n\n\nPython\n\ndataset = simulator.sample(1_000)\nprior = {k: v if k in param_keys for k, v in dataset.items()}\nposterior = approximator.sample(500, conditions = dataset)"
  },
  {
    "objectID": "slides/amortized-inference.html#simulation-based-calibration-sbc-talts2018validating",
    "href": "slides/amortized-inference.html#simulation-based-calibration-sbc-talts2018validating",
    "title": "Amortized Bayesian Inference",
    "section": "Simulation-based calibration (SBC, Talts et al., 2018)",
    "text": "Simulation-based calibration (SBC, Talts et al., 2018)\n\nTesting computational faithfulness of a posterior approximator\nPosterior distribution averaged over prior predictive distribution is the same as the prior distribution\n\n\\[\np(\\theta) = \\int \\int p(\\theta \\mid \\tilde{y}) \\underbrace{p(\\tilde{y} \\mid \\tilde{\\theta}) p(\\tilde{\\theta})}_{\\text{Prior predictives}} d\\tilde{\\theta} d \\tilde{y}\n\\]"
  },
  {
    "objectID": "slides/amortized-inference.html#simulation-based-calibration",
    "href": "slides/amortized-inference.html#simulation-based-calibration",
    "title": "Amortized Bayesian Inference",
    "section": "Simulation-based calibration",
    "text": "Simulation-based calibration\n\nDraw \\(N\\) prior predictive datasets \\((\\theta_i^{\\text{sim}}, y_i^{\\text{sim}}) \\sim p(\\theta, y)\\)\nFor each data set \\(y_i\\), draw \\(M\\) samples from the approximate posterior: \\(\\theta_{ij} \\sim q(\\theta \\mid y_i^{\\text{sim}})\\)\nCalculate rank statistic \\(r_i = \\sum_{j=1}^M \\text{I}\\big(\\theta_{ij} &lt; \\theta_i^{\\text{sim}}\\big)\\)"
  },
  {
    "objectID": "slides/amortized-inference.html#simulation-based-calibration-1",
    "href": "slides/amortized-inference.html#simulation-based-calibration-1",
    "title": "Amortized Bayesian Inference",
    "section": "Simulation-based calibration",
    "text": "Simulation-based calibration\n\n\nSimulate\n\\[\n\\begin{aligned}\n\\theta^{\\text{sim}} & \\sim p(\\theta) \\\\\ny^{\\text{sim}} &\\sim p(y \\mid \\theta^{\\text{sim}})\n\\end{aligned}\n\\]\n\nBy symmetry\n\\[\n\\begin{aligned}\n(\\theta^{\\text{sim}}, y^{\\text{sim}}) & \\sim p(\\theta, y) \\\\\n\\theta^{\\text{sim}} &\\sim p(\\theta \\mid y^{\\text{sim}})\n\\end{aligned}\n\\]\n\nCompute\n\\[\n\\begin{aligned}\n\\theta_1, \\dots, \\theta_M & \\sim q(\\theta \\mid y^{\\text{sim}}) \\\\\n\\end{aligned}\n\\]\nIf \\(q(\\theta \\mid y^{\\text{sim}}) = p(\\theta \\mid y^{\\text{sim}})\\), then the rank statistic of \\(\\theta^{\\text{sim}}\\) is uniform."
  },
  {
    "objectID": "slides/amortized-inference.html#visualizing-sbc",
    "href": "slides/amortized-inference.html#visualizing-sbc",
    "title": "Amortized Bayesian Inference",
    "section": "Visualizing SBC",
    "text": "Visualizing SBC\n\nHistograms\nECDF\nECDF difference"
  },
  {
    "objectID": "slides/amortized-inference.html#sbc-histograms",
    "href": "slides/amortized-inference.html#sbc-histograms",
    "title": "Amortized Bayesian Inference",
    "section": "SBC Histograms",
    "text": "SBC Histograms\n\n\nPython\n\nfig=bf.diagnostics.calibration_histogram(\n    estimates=posterior, \n    targets=prior)"
  },
  {
    "objectID": "slides/amortized-inference.html#sbc-ecdf",
    "href": "slides/amortized-inference.html#sbc-ecdf",
    "title": "Amortized Bayesian Inference",
    "section": "SBC ECDF",
    "text": "SBC ECDF\n\n\nPython\n\nfig=bf.diagnostics.calibration_ecdf(\n    estimates=posterior, \n    targets=prior)"
  },
  {
    "objectID": "slides/amortized-inference.html#sbc-ecdf-difference",
    "href": "slides/amortized-inference.html#sbc-ecdf-difference",
    "title": "Amortized Bayesian Inference",
    "section": "SBC ECDF Difference",
    "text": "SBC ECDF Difference\n\n\nPython\n\nfig=bf.diagnostics.calibration_ecdf(\n    estimates=posterior, \n    targets=prior,\n    difference=True)"
  },
  {
    "objectID": "slides/amortized-inference.html#sbc-interpretation",
    "href": "slides/amortized-inference.html#sbc-interpretation",
    "title": "Amortized Bayesian Inference",
    "section": "SBC interpretation",
    "text": "SBC interpretation\n\nNecessary but not sufficient condition\n\n✅ All faithful approximators should pass the SBC check\n⚠️ An unfaithful approximator may pass the SBC check\n\nDepends on\n\nSimulation budget (how many datasets)\nApproximation precision (how many posterior draws per data set)\n\\(\\rightarrow\\) degree/ways of miscalibration, rather than ok/not ok"
  },
  {
    "objectID": "slides/amortized-inference.html#what-if-sbc-check-fails",
    "href": "slides/amortized-inference.html#what-if-sbc-check-fails",
    "title": "Amortized Bayesian Inference",
    "section": "What if SBC check fails?",
    "text": "What if SBC check fails?\n\nPossible causes:\n\nUnderfitting \\(\\rightarrow\\) increase expresiveness of inference or summary network, increase training budget\nOverfitting \\(\\rightarrow\\) decrease expressiveness of inference or summary network, increase training budget\nCoding error \\(\\rightarrow\\) check for errors in the simulator, setting up the approximator\nFundamental problem with the statistical model \\(\\rightarrow\\) change the statistical model"
  },
  {
    "objectID": "slides/amortized-inference.html#posterior-z-score",
    "href": "slides/amortized-inference.html#posterior-z-score",
    "title": "Amortized Bayesian Inference",
    "section": "Posterior z-score",
    "text": "Posterior z-score\n\nHow well does the estimated posterior mean match the true parameter used for simulating the data?\n\n\\[\nz = \\frac{\\text{mean}(\\theta_i) - \\theta^{\\text{sim}}}{\\text{sd}(\\theta_i)}\n\\]"
  },
  {
    "objectID": "slides/amortized-inference.html#posterior-contraction",
    "href": "slides/amortized-inference.html#posterior-contraction",
    "title": "Amortized Bayesian Inference",
    "section": "Posterior contraction",
    "text": "Posterior contraction\n\nHow much uncertainty is removed after updating the prior to posterior?\n\n\\[\n\\text{contraction} = 1 - \\frac{\\text{sd}(\\theta_i)}{\\text{sd}(\\theta^{\\text{sim}})}\n\\]"
  },
  {
    "objectID": "slides/amortized-inference.html#z-score-vs.-contraction-plot",
    "href": "slides/amortized-inference.html#z-score-vs.-contraction-plot",
    "title": "Amortized Bayesian Inference",
    "section": "Z-score vs. contraction plot",
    "text": "Z-score vs. contraction plot\n\n\nPython\n\nfig=bf.diagnostics.plots.z_score_contraction(\n    estimates=posterior, \n    targets=prior)"
  },
  {
    "objectID": "slides/amortized-inference.html#parameter-recovery",
    "href": "slides/amortized-inference.html#parameter-recovery",
    "title": "Amortized Bayesian Inference",
    "section": "Parameter recovery",
    "text": "Parameter recovery\n\nPlot the true parameter values \\(\\theta^{\\text{sim}}\\) against a posterior point estimate (mean, median)\n\n\n\nPython\n\nfig=bf.diagnostics.plots.recovery(estimates=posterior, targets=prior)"
  },
  {
    "objectID": "slides/amortized-inference.html#what-if-i-get-poor-results",
    "href": "slides/amortized-inference.html#what-if-i-get-poor-results",
    "title": "Amortized Bayesian Inference",
    "section": "What if I get poor results",
    "text": "What if I get poor results\n\nPossible causes:\n\nPoor calibration of the approximator \\(\\rightarrow\\) see SBC\nPoor identification of the parameters\n\nUse more informative priors\nChange the model\nAdd more data (sample size, additional variables)"
  },
  {
    "objectID": "slides/amortized-inference.html#obtain-posterior-samples",
    "href": "slides/amortized-inference.html#obtain-posterior-samples",
    "title": "Amortized Bayesian Inference",
    "section": "Obtain posterior samples",
    "text": "Obtain posterior samples\n\n\n\nPython\n\ndata = dict(y = ...)\nposterior = approximator.sample(1000, conditions=data)\n\nfig=bf.diagnostics.plots.pairs_posterior(estimates=posterior)"
  },
  {
    "objectID": "slides/amortized-inference.html#model-misspecification",
    "href": "slides/amortized-inference.html#model-misspecification",
    "title": "Amortized Bayesian Inference",
    "section": "Model misspecification",
    "text": "Model misspecification\n\nPrior misspecification\nLikelihood misspecification\n\n\\(\\rightarrow\\) Approximator may not be trusted"
  },
  {
    "objectID": "slides/amortized-inference.html#posterior-predictive-checks",
    "href": "slides/amortized-inference.html#posterior-predictive-checks",
    "title": "Amortized Bayesian Inference",
    "section": "Posterior predictive checks",
    "text": "Posterior predictive checks\n\nUse posterior parameter posterior to simulate data from the simulator\nCompare simulated data to observed data\n\nVisual checks - histograms, ecdf plots, scatter plots, …\nComparing summary statistics - means, variances, …"
  },
  {
    "objectID": "slides/amortized-inference.html#use-summary-space",
    "href": "slides/amortized-inference.html#use-summary-space",
    "title": "Amortized Bayesian Inference",
    "section": "Use summary space",
    "text": "Use summary space\n\nAdd a base distribution to the summary network, e.g.\n\n\n\nPython\n\nsummary_network = bf.networks.Deepset(base_distribution=\"normal\")\n\n\nSchmitt et al. (2023)"
  },
  {
    "objectID": "slides/amortized-inference.html#uses-of-bayesflow",
    "href": "slides/amortized-inference.html#uses-of-bayesflow",
    "title": "Amortized Bayesian Inference",
    "section": "Uses of BayesFlow",
    "text": "Uses of BayesFlow\nIn addition to learning \\(p(\\theta \\mid x)\\):\n\nGenerative modeling tasks\nSurrogate likelihood: \\(p(x \\mid \\theta)\\) (Radev, Schmitt, Pratz, et al., 2023)\nModel comparison: \\(p(\\mathcal{M} \\mid x)\\) (Elsemüller et al., 2024; Radev et al., 2021)\nAmortized point estimation: \\(\\hat{\\theta}\\) (Sainsbury-Dale et al., 2024)"
  },
  {
    "objectID": "slides/amortized-inference.html#complex-models",
    "href": "slides/amortized-inference.html#complex-models",
    "title": "Amortized Bayesian Inference",
    "section": "Complex models",
    "text": "Complex models\n\nThink about possible factorizations of the model\n\nSplit the problem into multiple smaller pieces\n\nExamples:\n\nMultilevel models (Habermann et al., 2024)\nMixture models (Kucharský & Bürkner, 2025)"
  },
  {
    "objectID": "slides/amortized-inference.html#references",
    "href": "slides/amortized-inference.html#references",
    "title": "Amortized Bayesian Inference",
    "section": "References",
    "text": "References\n\n\n\n\nElsemüller, L., Schnuerch, M., Bürkner, P.-C., & Radev, S. T. (2024). A deep learning method for comparing bayesian hierarchical models. Psychological Methods, Advance online publication. https://doi.org/10.1037/met0000645\n\n\nHabermann, D., Schmitt, M., Kühmichel, L., Bulling, A., Radev, S. T., & Bürkner, P.-C. (2024). Amortized bayesian multilevel models. arXiv Preprint arXiv:2408.13230.\n\n\nKucharský, Š., & Bürkner, P. C. (2025). Amortized bayesian mixture models. arXiv Preprint arXiv:2501.10229.\n\n\nRadev, S. T., D’Alessandro, M., Mertens, U. K., Voss, A., Köthe, U., & Bürkner, P.-C. (2021). Amortized bayesian model comparison with evidential deep learning. IEEE Transactions on Neural Networks and Learning Systems, 34(8), 4903–4917.\n\n\nRadev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., & Köthe, U. (2020). BayesFlow: Learning complex stochastic models with invertible neural networks. IEEE Transactions on Neural Networks and Learning Systems, 33(4), 1452–1466.\n\n\nRadev, S. T., Schmitt, M., Pratz, V., Picchini, U., Koethe, U., & Bürkner, P.-C. (2023). JANA: Jointly amortized neural approximation of complex bayesian models. The 39th Conference on Uncertainty in Artificial Intelligence. https://openreview.net/forum?id=dS3wVICQrU0\n\n\nRadev, S. T., Schmitt, M., Schumacher, L., Elsemüller, L., Pratz, V., Schälte, Y., Köthe, U., & Bürkner, P.-C. (2023). BayesFlow: Amortized bayesian workflows with neural networks. arXiv. https://arxiv.org/abs/2306.16015\n\n\nSainsbury-Dale, M., Zammit-Mangion, A., & Huser, R. (2024). Likelihood-free parameter estimation with neural bayes estimators. The American Statistician, 78(1), 1–14.\n\n\nSchad, D. J., Betancourt, M., & Vasishth, S. (2021). Toward a principled Bayesian workflow in cognitive science. Psychological Methods, 26(1), 103.\n\n\nSchmitt, M., Bürkner, P.-C., Köthe, U., & Radev, S. T. (2023). Detecting model misspecification in amortized Bayesian inference with neural networks. DAGM German Conference on Pattern Recognition, 541–557.\n\n\nTalts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating bayesian inference algorithms with simulation-based calibration. arXiv Preprint arXiv:1804.06788."
  },
  {
    "objectID": "slides/generative-architectures.html#generative-models",
    "href": "slides/generative-architectures.html#generative-models",
    "title": "Generative Neural Networks",
    "section": "Generative models",
    "text": "Generative models\nLearn \\(p_X\\) given a set of training data \\(x_i, \\dots, x_n\\)\n\n\nSampling \\(x \\sim p_X\\)\nDensity evaluation \\(p_X(x)\\)"
  },
  {
    "objectID": "slides/generative-architectures.html#mixture-model",
    "href": "slides/generative-architectures.html#mixture-model",
    "title": "Generative Neural Networks",
    "section": "Mixture model",
    "text": "Mixture model\nWeighted sum of multiple simpler distributions, e.g., Normal \\[p_X(X) = \\sum_k^K w_k \\times \\text{Normal}(X; \\mu_k, \\sigma_k)\\]\n\nSampling and evaluating straightforward\nTheoretically can represent any distribution\nPractically, does not scale well"
  },
  {
    "objectID": "slides/generative-architectures.html#many-architectures",
    "href": "slides/generative-architectures.html#many-architectures",
    "title": "Generative Neural Networks",
    "section": "Many architectures",
    "text": "Many architectures\n\nMarkov random fields (Li, 2009)\nGenerative adversarial networks (GAN, Goodfellow et al., 2014)\nVariational autoencoders (VAE, Kingma et al., 2013)\nDiffusion models (Song et al., 2020)\nConsistency models (Song et al., 2023)\nNormalizing flows (Kobyzev et al., 2020; Papamakarios et al., 2021)\nFlow matching (Lipman et al., 2022)"
  },
  {
    "objectID": "slides/generative-architectures.html#common-idea",
    "href": "slides/generative-architectures.html#common-idea",
    "title": "Generative Neural Networks",
    "section": "Common idea",
    "text": "Common idea\nMap \\(p_X\\) to a base distribution \\(p_Z\\) through some operation \\(g\\)\n\\[\nx \\sim g(z) \\text{ where } z \\sim p_Z\n\\]\n\nSource: learnopencv.com"
  },
  {
    "objectID": "slides/generative-architectures.html#normalizing-flows-1",
    "href": "slides/generative-architectures.html#normalizing-flows-1",
    "title": "Generative Neural Networks",
    "section": "Normalizing flows",
    "text": "Normalizing flows\nBuilt on invertible transformations of random variables\n\nFind \\(f\\) such that \\(f(X) = Z \\sim \\text{Normal}(0, I)\\)\n\n\\(f\\) normalizes \\(X\\)\n\n\n\n\n\n\n\n \n\n\n\\(f\\)\n\n\n \n\n\n\n\n\n\n\n\\[\\rightarrow\\]\n\n\n\n\n\n\n\nFigure 1: Forward direction"
  },
  {
    "objectID": "slides/generative-architectures.html#sampling",
    "href": "slides/generative-architectures.html#sampling",
    "title": "Generative Neural Networks",
    "section": "Sampling",
    "text": "Sampling\n\nSample \\(z \\sim p_Z\\) (e.g., Normal)\nObtain \\(x = f^{-1}(z)\\)\n\n\n\n\n\n\n\n \n\n\n\\(f^{-1}\\)\n\n\n \n\n\n\n\n\n\n\n\\[\\leftarrow\\]\n\n\n\n\n\n\n\nFigure 2: Backward direction"
  },
  {
    "objectID": "slides/generative-architectures.html#density-evaluation",
    "href": "slides/generative-architectures.html#density-evaluation",
    "title": "Generative Neural Networks",
    "section": "Density evaluation",
    "text": "Density evaluation\nChange of variables formula\n\\[\np_X(x) = p_Z(f(x)) \\left| \\det{J}_f(x) \\right|\n\\]\n\nExpress \\(p_X\\) using \\(p_Z\\) and the transform \\(f\\)\n\\(\\left| \\det{J}_f(x) \\right|\\): Absolute value of the determinant of the Jacobian matrix\n\n“Jacobian” for short\nVolume correction term"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---intuition",
    "href": "slides/generative-architectures.html#change-of-variables---intuition",
    "title": "Generative Neural Networks",
    "section": "Change of variables - intuition",
    "text": "Change of variables - intuition\n\n\n\\[Z \\sim \\text{Uniform}(0, 1)\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---intuition-1",
    "href": "slides/generative-architectures.html#change-of-variables---intuition-1",
    "title": "Generative Neural Networks",
    "section": "Change of variables - intuition",
    "text": "Change of variables - intuition\n\n\n\\[Z \\sim \\text{Uniform}(0, 1)\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---intuition-2",
    "href": "slides/generative-architectures.html#change-of-variables---intuition-2",
    "title": "Generative Neural Networks",
    "section": "Change of variables - intuition",
    "text": "Change of variables - intuition\n\n\n\\[Z \\sim \\text{Uniform}(0, 1)\\]\n\n\n\\[X = 2Z - 1\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---intuition-3",
    "href": "slides/generative-architectures.html#change-of-variables---intuition-3",
    "title": "Generative Neural Networks",
    "section": "Change of variables - intuition",
    "text": "Change of variables - intuition\n\n\n\\[Z \\sim \\text{Uniform}(0, 1)\\]\n\n\n\\[X = 2Z - 1\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---affine-transform",
    "href": "slides/generative-architectures.html#change-of-variables---affine-transform",
    "title": "Generative Neural Networks",
    "section": "Change of variables - affine transform",
    "text": "Change of variables - affine transform\n\\[f: Z = a X + b\\]\n\nshift by \\(b\\): no effect\nscale by a constant \\(a\\): multiply by \\(a\\)\n\n\\[p_X(x) = p_Z(f(x)) \\times a\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---affine-transform-1",
    "href": "slides/generative-architectures.html#change-of-variables---affine-transform-1",
    "title": "Generative Neural Networks",
    "section": "Change of variables - affine transform",
    "text": "Change of variables - affine transform\n\nExample\n\n\n\\[\n\\scriptsize\n\\begin{aligned}\np_Z(z) & = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} z^2 \\right) \\\\[10pt]\nf: Z & = \\frac{(X - \\mu)}{\\sigma} \\\\\n\\end{aligned}\n\\]\n\n\\[\n\\scriptsize\n\\begin{aligned}\np_X(x) & = p_Z(f(x)) \\times a \\\\[10pt]\n& = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} f(x)^2 \\right) \\times a \\\\[10pt]\n& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2 \\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---more-formally",
    "href": "slides/generative-architectures.html#change-of-variables---more-formally",
    "title": "Generative Neural Networks",
    "section": "Change of variables - more formally",
    "text": "Change of variables - more formally\n\\[\np_X(x) = p_Z(f(x))  \\left| \\frac{d}{dx} f(x) \\right|\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---more-formally-1",
    "href": "slides/generative-architectures.html#change-of-variables---more-formally-1",
    "title": "Generative Neural Networks",
    "section": "Change of variables - more formally",
    "text": "Change of variables - more formally\n\\[\np_X(x) = p_Z(f(x))  \\left| \\frac{d}{dx} f(x) \\right|\n\\]\nExample\n\n\n\\[\n\\scriptsize\n\\begin{align}\nf: Z & = \\log(X) \\\\[10pt]\np_Z(z) & = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} z^2 \\right)\n\\end{align}\n\\]\n\n\\[\n\\scriptsize\n\\begin{align}\n\\frac{d}{dx} f(x) & = \\frac{d}{dx} \\log(x) = \\frac{1}{x} \\\\[10pt]\np_X(x) & = \\frac{1}{x\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} \\log(x)^2\\right)\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---multivariate",
    "href": "slides/generative-architectures.html#change-of-variables---multivariate",
    "title": "Generative Neural Networks",
    "section": "Change of variables - multivariate",
    "text": "Change of variables - multivariate\n\\[\np_X(x) = p_Z(f(x)) \\left| \\det{J}_f(x) \\right|\n\\]\n\n\\[\nJ_f(x) = \\begin{bmatrix}\n\\frac{\\partial z_1}{\\partial x_1} & \\dots & \\frac{\\partial z_1}{\\partial x_K} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial z_K}{\\partial x_1} & \\dots & \\frac{\\partial z_K}{\\partial x_K}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#change-of-variables---multivariate-1",
    "href": "slides/generative-architectures.html#change-of-variables---multivariate-1",
    "title": "Generative Neural Networks",
    "section": "Change of variables - multivariate",
    "text": "Change of variables - multivariate\n\\[f\\left(\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}\\right) = \\begin{bmatrix} x_1^2 x_2 \\\\ 3x_1 + \\sin x_2 \\end{bmatrix} = \\begin{bmatrix}z_1 \\\\ z_2\\end{bmatrix}\\]\n\n\\[J_f(x) = \\begin{bmatrix}\n\\frac{\\partial z_1}{\\partial x_1} & \\frac{\\partial z_1}{\\partial x_2} \\\\\n\\frac{\\partial z_2}{\\partial x_1} & \\frac{\\partial z_2}{\\partial x_2}\n\\end{bmatrix} = \\begin{bmatrix} 2x_1x_2 & x_1^2 \\\\ 3 & \\cos x_2 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#normalizing-flow",
    "href": "slides/generative-architectures.html#normalizing-flow",
    "title": "Generative Neural Networks",
    "section": "Normalizing flow",
    "text": "Normalizing flow\n\\[\np_X(x) = p_Z(f(x)) \\left| \\det{J}_f(x) \\right|\n\\]\nDefine a \\(f\\) as a neural network with trainable weights \\(\\phi\\)\n\nTraining\nMaximum likelihood (or rather: negative log likelihood)\n\\[\n\\arg \\min_\\phi - \\sum_{i=1}^n \\log p_Z(f(x_i \\mid \\phi)) + \\log \\left| \\det{J}_f(x_i \\mid \\phi) \\right|\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-f",
    "href": "slides/generative-architectures.html#flow-f",
    "title": "Generative Neural Networks",
    "section": "Flow \\(f\\)",
    "text": "Flow \\(f\\)\n\nChallenge\n\nSampling: Invertible (\\(f^{-1}\\))\nTraining:\n\nDifferentiable\nComputationally efficient jacobian\n\nExpressive to represent non-trivial distributions"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-composition",
    "href": "slides/generative-architectures.html#flow-composition",
    "title": "Generative Neural Networks",
    "section": "Flow composition",
    "text": "Flow composition\nInvertible and differentiable functions are “closed” under composition\n\\[\nf = f_L \\circ f_{L-1} \\circ \\dots \\circ f_1 \\\\\n\\]\n\n\n\n\n\n \n\n\n\\(f_1\\)\n\n\n \n\n\n\\(f_2\\)\n\n\n \n\n\n\\(f_3\\)\n\n\n \n\n\n\n\n\n\n\n\\(\\rightarrow\\)\n\n\n\n\n\n\\(\\rightarrow\\)\n\n\n\n\n\n\\(\\rightarrow\\)\n\n\n\n\n\n\n\nFigure 3: Flow composition in forward direction"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-composition---inverse",
    "href": "slides/generative-architectures.html#flow-composition---inverse",
    "title": "Generative Neural Networks",
    "section": "Flow composition - inverse",
    "text": "Flow composition - inverse\nTo invert a flow composition, we invert individual flows and run them in the opposite order\n\\[\nf^{-1} = f_1^{-1} \\circ f_2 ^{-1} \\circ \\dots \\circ f_L^{-1} \\\\\n\\]\n\n\n\n\n\n \n\n\n\\(f_1^{-1}\\)\n\n\n \n\n\n\\(f_2^{-1}\\)\n\n\n \n\n\n\\(f_3^{-1}\\)\n\n\n \n\n\n\n\n\n\n\n\\(\\leftarrow\\)\n\n\n\n\n\n\\(\\leftarrow\\)\n\n\n\n\n\n\\(\\leftarrow\\)\n\n\n\n\n\n\n\nFigure 4: Flow composition in backward (inverse) direction"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-composition---jacobian",
    "href": "slides/generative-architectures.html#flow-composition---jacobian",
    "title": "Generative Neural Networks",
    "section": "Flow composition - Jacobian",
    "text": "Flow composition - Jacobian\n\nChain rule \\[\n\\left| \\det{J}_f(x) \\right| = \\left| \\det \\prod_{l=1}^L J_{f_l}(x)\\right| = \\prod_{l=1}^L \\left| \\det{J}_{f_l}(x)\\right|\n\\]\nif we have a Jacobian for each individual transformation, then we have a Jacobian for their composition \\[\n\\arg \\min_\\phi \\sum_{i=1}^n \\log p_Z(f(x_i \\mid \\phi)) + \\sum_{l=1}^L \\log \\left| \\det{J}_{f_l}(x_i \\mid \\phi) \\right|\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#linear-flow",
    "href": "slides/generative-architectures.html#linear-flow",
    "title": "Generative Neural Networks",
    "section": "Linear flow",
    "text": "Linear flow\n\n\\[\nf(x) = Ax + b\n\\]\n\ninverse: \\(f^{-1}(z) = A^{-1}(x - b)\\)\nJacobian: \\(\\left| \\det{J}_f(x) \\right| = \\left| \\det{A} \\right|\\)\nLimitations:\n\nNot expressive (composition of linear functions is a linear function)\nJacobian/inverse may be in \\(\\mathcal{O}(p^3)\\)"
  },
  {
    "objectID": "slides/generative-architectures.html#coupling-flows",
    "href": "slides/generative-architectures.html#coupling-flows",
    "title": "Generative Neural Networks",
    "section": "Coupling flows",
    "text": "Coupling flows\n\nIncreasing expresiveness while potentially decreasing computational costs\nA coupling flow is a way to construct non-linear flows\n\n\nSplit the data in two disjoint subsets: \\(x = (x_A, x_B)\\)\nCompute parameters conditionally on one subset: \\(\\theta(x_A)\\)\nApply transformation to the other subset: \\(z_B = f(x_B \\mid \\theta(x_A))\\)\nConcatenate \\(z = (x_A, z_B)\\)"
  },
  {
    "objectID": "slides/generative-architectures.html#coupling-flow-forward",
    "href": "slides/generative-architectures.html#coupling-flow-forward",
    "title": "Generative Neural Networks",
    "section": "Coupling flow: Forward",
    "text": "Coupling flow: Forward"
  },
  {
    "objectID": "slides/generative-architectures.html#coupling-flow-inverse",
    "href": "slides/generative-architectures.html#coupling-flow-inverse",
    "title": "Generative Neural Networks",
    "section": "Coupling flow: Inverse",
    "text": "Coupling flow: Inverse"
  },
  {
    "objectID": "slides/generative-architectures.html#coupling-flow-trick",
    "href": "slides/generative-architectures.html#coupling-flow-trick",
    "title": "Generative Neural Networks",
    "section": "Coupling flow trick",
    "text": "Coupling flow trick\n\nJacobian\n\n\\[ J_f =\n\\begin{bmatrix}\n\\text{I} & 0 \\\\\n\\frac{\\partial}{\\partial x_A}f(x_B \\mid \\theta(x_A)) & J_f(x_B \\mid \\theta(x_A))\n\\end{bmatrix}\n\\]\n\nDeterminant\n\n\\[\n\\det{J}_f = \\det(\\text{I}) \\times \\det{J}_f(x_B \\mid \\theta(x_A)) = \\det{J}_f(x_B \\mid \\theta(x_A))\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#coupling-flow-trick-1",
    "href": "slides/generative-architectures.html#coupling-flow-trick-1",
    "title": "Generative Neural Networks",
    "section": "Coupling flow trick",
    "text": "Coupling flow trick\n\n\\(f(x_B\\mid\\theta(x_A))\\) needs to be differentiable and invertible\n\neasy to calculate determinant Jacobian…\n\n\\(\\theta(x_A)\\) can be arbitrarily complex\n\nnon-linear,\nnon-invertible\n\\(\\rightarrow\\) neural network\n\n\n\n\nStack multiple coupling blocks and permute \\(x_{A}\\) and \\(x_{B}\\)"
  },
  {
    "objectID": "slides/generative-architectures.html#affine-coupling-dinh2016density",
    "href": "slides/generative-architectures.html#affine-coupling-dinh2016density",
    "title": "Generative Neural Networks",
    "section": "Affine coupling (Dinh et al., 2016)",
    "text": "Affine coupling (Dinh et al., 2016)\n\n\\(\\theta(x_A)\\): Trainable coupling networks, e.g., MLP\n\nOutput: Shift \\(\\mu\\) and scale \\(\\sigma\\)\n\nLinear (affine) transform function \\(f(x_B\\mid\\theta(x_A)) = \\frac{x_B - \\mu(x_A)}{\\sigma(x_A)}\\)\nJacobian: \\(-\\log{\\sigma(x_A)}\\)"
  },
  {
    "objectID": "slides/generative-architectures.html#spline-coupling-muller2019neural",
    "href": "slides/generative-architectures.html#spline-coupling-muller2019neural",
    "title": "Generative Neural Networks",
    "section": "Spline coupling (Müller et al., 2019)",
    "text": "Spline coupling (Müller et al., 2019)\n\n\n\nTransformation: Splines\n\n“Piecewise polynomials”\n\nMore expressive\nEasier to overfit\nSlower at training and inference\n\n\n\n\n\nFigure from Durkan et al. (2019)"
  },
  {
    "objectID": "slides/generative-architectures.html#exercise---moons",
    "href": "slides/generative-architectures.html#exercise---moons",
    "title": "Generative Neural Networks",
    "section": "Exercise - Moons",
    "text": "Exercise - Moons\nBuild your own affine coupling normalizing flow!\n\n\n\nForward\n\n\nBackward"
  },
  {
    "objectID": "slides/generative-architectures.html#idea",
    "href": "slides/generative-architectures.html#idea",
    "title": "Generative Neural Networks",
    "section": "Idea",
    "text": "Idea\n\nNormalizing flows transform X into Z in a set of discrete steps\nBut why not take one smooth/continuous transformation?"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-matching",
    "href": "slides/generative-architectures.html#flow-matching",
    "title": "Generative Neural Networks",
    "section": "Flow matching",
    "text": "Flow matching\n\nDefines a flow that transforms a distribution over time\n\n\\(p_{t=0} = p_z\\) - Base distribution\n\\(p_{t=1} = q = p_x\\) - Data distribution\n\n\n\n\nLipman et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-and-velocity",
    "href": "slides/generative-architectures.html#flow-and-velocity",
    "title": "Generative Neural Networks",
    "section": "Flow and velocity",
    "text": "Flow and velocity\n\nFlow defines \\(X_t = \\phi_t(X_0)\\)\nTime dependent vector field: \\(\\frac{d}{dt} \\phi_t(x) = u_t(\\phi_t(x))\\)\nModel \\(u_t\\) with a neural network\n\n\n\nLipman et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#flow-matching-1",
    "href": "slides/generative-architectures.html#flow-matching-1",
    "title": "Generative Neural Networks",
    "section": "Flow matching",
    "text": "Flow matching\n\\[\n\\begin{aligned}\n\\mathbb{E}_{t, X_t}|| u_{t,\\theta}(X_t) - u_t(X_t) ||^2 \\\\ t\\sim\\text{Uniform}(0,1) \\\\ X_t \\sim p_t(X_t)\n\\end{aligned}\n\\]\n\nLipman et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#conditional-flow-matching",
    "href": "slides/generative-architectures.html#conditional-flow-matching",
    "title": "Generative Neural Networks",
    "section": "Conditional Flow Matching",
    "text": "Conditional Flow Matching\nLinear probability path\n\\[X_t = (1-t) X_0 + t X_1\\]\nVelocity\n\\[u_t(X_t \\mid X_1, X_0) = X_1 - X_0\\]\n\nLipman et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#conditional-flow-matching-1",
    "href": "slides/generative-architectures.html#conditional-flow-matching-1",
    "title": "Generative Neural Networks",
    "section": "Conditional Flow Matching",
    "text": "Conditional Flow Matching\n \\[\n\\begin{aligned}\n\\mathbb{E}_{t, X_t}|| u_{t,\\theta}\\big(\\underbrace{(1-t) X_0 + t X_1)}_{X_t}\\big) - (\\underbrace{X_1-X_0}_{u_t}) ||^2 \\\\ t\\sim\\text{Uniform}(0,1) \\\\ X_0 \\sim p_0 \\\\ X_1 \\sim p_1\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/generative-architectures.html#conditional-vs-marginal-paths",
    "href": "slides/generative-architectures.html#conditional-vs-marginal-paths",
    "title": "Generative Neural Networks",
    "section": "Conditional vs Marginal paths",
    "text": "Conditional vs Marginal paths\n\n\n\n\n\n\n\n\nConditional path\n\n\n\n\n\n\n\nMarginal path\n\n\n\n\n\n\nFigure 5: Fjelde et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#optimal-transport",
    "href": "slides/generative-architectures.html#optimal-transport",
    "title": "Generative Neural Networks",
    "section": "Optimal transport",
    "text": "Optimal transport\n\nIndependent coupling \\(p(X_0, X_1) = p(X_0) p(X_1)\\)\nOptimal transport coupling \\(p(X_0, X_1) = \\pi(X_0, X_1)\\)\n\nMinimise transport cost (e.g., Wasserstein distance)\nFor batches (Pooladian et al., 2023)\n\n\n\n\nFigure 6: Fjelde et al. (2024)"
  },
  {
    "objectID": "slides/generative-architectures.html#exercise",
    "href": "slides/generative-architectures.html#exercise",
    "title": "Generative Neural Networks",
    "section": "Exercise",
    "text": "Exercise"
  },
  {
    "objectID": "slides/generative-architectures.html#exercise-1",
    "href": "slides/generative-architectures.html#exercise-1",
    "title": "Generative Neural Networks",
    "section": "Exercise",
    "text": "Exercise"
  },
  {
    "objectID": "slides/generative-architectures.html#references",
    "href": "slides/generative-architectures.html#references",
    "title": "Generative Neural Networks",
    "section": "References",
    "text": "References\n\n\n\n\nDinh, L., Sohl-Dickstein, J., & Bengio, S. (2016). Density estimation using real nvp. arXiv Preprint arXiv:1605.08803.\n\n\nDurkan, C., Bekasov, A., Murray, I., & Papamakarios, G. (2019). Neural spline flows. Advances in Neural Information Processing Systems, 32.\n\n\nFjelde, T., Mathieu, E., & Dutordoir, V. (2024). An Introduction to Flow Matching. https://mlg.eng.cam.ac.uk/blog/2024/01/20/flow-matching.html\n\n\nGoodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y. (2014). Generative adversarial nets. Advances in Neural Information Processing Systems, 27.\n\n\nKingma, D. P., Welling, M., et al. (2013). Auto-encoding variational bayes. Banff, Canada.\n\n\nKobyzev, I., Prince, S. J., & Brubaker, M. A. (2020). Normalizing flows: An introduction and review of current methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(11), 3964–3979.\n\n\nLi, S. Z. (2009). Markov random field modeling in image analysis. Springer Science & Business Media.\n\n\nLipman, Y., Chen, R. T., Ben-Hamu, H., Nickel, M., & Le, M. (2022). Flow matching for generative modeling. arXiv Preprint arXiv:2210.02747.\n\n\nLipman, Y., Havasi, M., Holderrieth, P., Shaul, N., Le, M., Karrer, B., Chen, R. T. Q., Lopez-Paz, D., Ben-Hamu, H., & Gat, I. (2024). Flow matching guide and code. https://arxiv.org/abs/2412.06264\n\n\nMüller, T., McWilliams, B., Rousselle, F., Gross, M., & Novák, J. (2019). Neural importance sampling. ACM Transactions on Graphics (ToG), 38(5), 1–19.\n\n\nPapamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., & Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. Journal of Machine Learning Research, 22(57), 1–64.\n\n\nPooladian, A.-A., Ben-Hamu, H., Domingo-Enrich, C., Amos, B., Lipman, Y., & Chen, R. T. (2023). Multisample flow matching: Straightening flows with minibatch couplings. arXiv Preprint arXiv:2304.14772.\n\n\nSong, Y., Dhariwal, P., Chen, M., & Sutskever, I. (2023). Consistency models.\n\n\nSong, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv Preprint arXiv:2011.13456."
  },
  {
    "objectID": "exercises/flow-matching-swiss-roll.html",
    "href": "exercises/flow-matching-swiss-roll.html",
    "title": "Flow matching with conditioning",
    "section": "",
    "text": "In the previous exercises, we trained a normalizing flow and a flow matching models to reproduce one distribution.\nIn this example, we will expand the concept a little bit and show that a single generative model can be trained to generate different distributions, by conditioning on additional variables.\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport tensorflow as tf\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_swiss_roll\nfrom math import pi"
  },
  {
    "objectID": "exercises/flow-matching-swiss-roll.html#the-data",
    "href": "exercises/flow-matching-swiss-roll.html#the-data",
    "title": "Flow matching with conditioning",
    "section": "The data",
    "text": "The data\nWe will use the swiss roll data distribution available from the sklearn library. This distribution generates samples in 3D, but we will only focus on a 2D projection, since the third dimension is not very interesting.\n\nn_samples=1_000\n\n\ndata, _ = make_swiss_roll(n_samples, noise=1)\ndata = data[:,[0, -1]]\nfig=plt.scatter(data[:,0], data[:,1])\n\n\n\n\n\n\n\n\nTo show that generative models like flow matching can use other base distributions than the normal, we will also create a custom base distribution that samples values along a circle (a ring).\n\ndef make_ring(n_samples):\n    u = np.random.uniform(low=0, high=2*pi, size=(n_samples,1))\n    r = np.random.uniform(low=9, high=10, size=(n_samples,1))\n    x = r * np.sin(u)\n    y = r * np.cos(u)\n    return np.concatenate([x, y], axis=-1)\n    \n\nbase = make_ring(n_samples)\nfig=plt.scatter(base[:,0], base[:,1])"
  },
  {
    "objectID": "exercises/flow-matching-swiss-roll.html#the-model",
    "href": "exercises/flow-matching-swiss-roll.html#the-model",
    "title": "Flow matching with conditioning",
    "section": "The model",
    "text": "The model\nThe model is the same as in the datasaurus flow matching exercise except that the velocity network also accepts additional variables that we here call condition. This allows us to train the network to generate different distributions, depending on the values of condition that we choose.\n\nclass FlowMatching(keras.Model):\n    def __init__(self, n_units, n_layers, dim=2):\n        \"\"\" Initiate the flow matching model object\n\n        Parameters\n        ----------\n        n_units: int\n            Number of units per each layer of the velocity MLP\n        n_layers: int\n            Number of layers of the velocity MLP\n        dim: int\n            Number of output dimensions (by default 2 because the datasaurus lives in 2D)\n        \"\"\"\n        super(FlowMatching, self).__init__()\n        self.dim = dim\n        self.velocity = keras.Sequential(\n            [keras.layers.Dense(n_units, activation=\"elu\") for _ in range(n_layers)]\n            )\n        self.velocity.add(keras.layers.Dense(dim))\n\n    def call(self, inputs):\n        \"\"\" Call the velocity vector\n\n        Parameters\n        ----------\n        inputs: dict\n            x_0: samples from the base distribution\n            x_1: samples from the data distribution\n            t:   samples of the time variable between [0, 1]\n            condition: some conditioning variables\n\n\n        Returns the velocity vector\n        \"\"\"\n        x_0, x_1, t, condition = inputs.values()\n        x_t = (1-t)*x_0 + t*x_1\n        x = keras.ops.concatenate([x_t, t, condition], axis=-1)\n        return self.velocity(x)\n\n    def step(self, x, t, dt, condition):\n        \"\"\" Make one step using the midpoint ODE solver\n\n        Parameters\n        ----------\n        x: tensor/array (batch_size, dim)\n            Samples of the variable x_t\n        t: tuple/array (batch_size,)\n            Samples of the time variable between [0, 1]\n        dt: float\n            The size of the time step\n        condition: some conditioning variables\n\n        Returns: tensor/array (batch_size, dim)\n            Samples of the variable x_{t+dt}\n        \"\"\"\n\n        t_start = np.zeros_like(x) + t\n        input_start = keras.ops.concatenate([x, t_start, condition], axis=-1)\n        v = self.velocity(input_start)\n        x_mid = x + v * dt / 2\n\n        t_mid = t_start + dt / 2\n        input_mid = keras.ops.concatenate([x_mid, t_mid, condition], axis=-1)\n        v = self.velocity(input_mid)\n        x_end = x + v * dt\n\n        return x_end\n\n    def run(self, x, steps, condition):\n        \"\"\" Run the ODE solver from t=0 to t=1\n\n        Parameters\n        ----------\n        x: tensor/array (batch_size, dim)\n            Samples from the base distribution, x_0\n        steps: int\n            Number of steps to make between t=0 and t=1\n        condition: some conditioning variables\n        \n        Returns: tensor/array (batch_size, dim)\n            Samples x_1 ~ p_1\n        \"\"\"\n\n        time = np.linspace(0, 1, steps+1)\n        output = []\n        output.append(x)\n        for i in range(steps):\n            x = self.step(x, time[i], time[i+1]-time[i], condition)\n            output.append(x)\n        \n        return output\n\n    def sample(self, n_samples, steps, condition):\n        \"\"\" Sample from the learned distribution\n\n        Parameters\n        ----------\n        n_samples: int\n            Number of samples to take\n        steps: int\n            Number of steps to make between t=0 and t=1 in the ODE\n        condition: some conditioning variables\n\n        Returns (array (batch_size, steps+1, dim)\n            Samples of x_t ~ p_t\n        \"\"\"\n        condition = np.array(condition)[np.newaxis,...]\n        condition = np.repeat(condition, repeats=n_samples, axis=0)\n        \n        x_0 = make_ring(n_samples)\n        x_1 = self.run(x_0, steps, condition)\n        return np.array(x_1).swapaxes(0, 1)\n\nOnce we defined our model class, we can instantiate a new flow matching model object.\n\nflow = FlowMatching(n_units=64, n_layers=8)"
  },
  {
    "objectID": "exercises/flow-matching-swiss-roll.html#training",
    "href": "exercises/flow-matching-swiss-roll.html#training",
    "title": "Flow matching with conditioning",
    "section": "Training",
    "text": "Training\nSimilarly as in the datasaurus exercise, we will use a dataset object to do our sampling. Here, we will always generate a fresh batch of new data - from the swiss roll distribution, and from the ring distribution.\nWe will also make a twist: We will randomly sample values of 1 or -1 for the x and y coordinate, which we use to scale the swiss roll data. This will produce 4 different variations of the swiss roll data, reflected along and \\(x\\) or \\(y\\) axis. The values of this scale will be passed to the velocity network as condition.\nOtherwise, the rest is the same as with the datasaurus.\n\nclass DataSet(keras.utils.PyDataset):\n    def __init__(self, batch_size, n_batches):\n        super().__init__()\n        self.n_batches=n_batches\n        self.batch_size = batch_size\n    \n    @property\n    def num_batches(self):\n        return self.n_batches\n\n    def __getitem__(self, index):\n        data, _ = make_swiss_roll(self.batch_size, noise=1)\n        data = data[:,[0, -1]]\n        condition = np.random.choice([1, -1], size=(batch_size, 2))\n        data = condition * data\n\n        base= make_ring(data.shape[0])\n        \n        t = np.random.uniform(low=0, high=1, size=data.shape[0])\n        t = np.repeat(t[:,np.newaxis], repeats=data.shape[1], axis=1)\n\n        target = data - base\n        return dict(x_0=base, x_1=data, t=t, condition=condition), target\n\nNext, we instantiate the dataset object, and define our schedule and optimizer, and compile the model.\n\nepochs=20\nbatches=1000\nbatch_size=512\n\ndataset=DataSet(batch_size=batch_size, n_batches=epochs*batches)\n\nschedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.01, decay_steps=epochs*batches)\noptimizer = keras.optimizers.Adam(schedule, global_clipnorm=1.0)\n\nflow.compile(\n    optimizer=optimizer,\n    loss=keras.losses.MeanSquaredError()\n)\n\nAgain, the same as with the datasaurus exercise, we can call the .fit method to train the model.\n\nhistory=flow.fit(x=dataset, epochs=epochs, steps_per_epoch=batches)\n\nEpoch 1/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - loss: 67.5142\nEpoch 2/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 60.5823\nEpoch 3/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 59.2506\nEpoch 4/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 58.8516\nEpoch 5/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 58.4735\nEpoch 6/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 58.0877\nEpoch 7/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 57.6959\nEpoch 8/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 57.6651\nEpoch 9/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 57.3689\nEpoch 10/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 57.1357\nEpoch 11/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.9357\nEpoch 12/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.5468\nEpoch 13/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.4292\nEpoch 14/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 56.2061\nEpoch 15/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.1961\nEpoch 16/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.1195\nEpoch 17/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 56.1653\nEpoch 18/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 55.8236\nEpoch 19/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 55.8725\nEpoch 20/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 55.6168\n\n\n\nf=plt.plot(history.history[\"loss\"])\n\n\n\n\n\n\n\n\nNow that we fitted the model, let’s see the samples it generates!\nHere we will loop over the possible combinations of the condition which is either -1 or 1 for \\(x\\) and \\(y\\) coordinate - leading to 4 different distributions produced by the flow matching model.\n\nfig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\nfor i, x_scale in enumerate([1, -1]):\n    for j, y_scale in enumerate([1, -1]):\n        condition = [x_scale, y_scale]\n        x = flow.sample(n_samples=n_samples, steps=100, condition=condition)\n        axs[i,j].scatter(x[:, -1, 0], x[:, -1, 1], s=10, alpha=0.5)\n        axs[i,j].set_title(\"x scale: {}, y scale {}\".format(x_scale, y_scale))\nfig.tight_layout()"
  },
  {
    "objectID": "exercises/normalizing-flow.html",
    "href": "exercises/normalizing-flow.html",
    "title": "Normalizing flow",
    "section": "",
    "text": "In this notebook, we will create our own normalizing flow model, and train it to reproduce the “moons” distribution available from the sklearn library.\nWe will use affine coupling layers to compose our normalizing flow.\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport tensorflow as tf\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom math import pi"
  },
  {
    "objectID": "exercises/normalizing-flow.html#the-data",
    "href": "exercises/normalizing-flow.html#the-data",
    "title": "Normalizing flow",
    "section": "The data",
    "text": "The data\nFirst, let’s visualise the data that we want to be able to reproduce with a normalizing flow.\n\nn_samples = 1_000\ndata, _ = make_moons(n_samples=n_samples, noise=0.05)\ndata.shape\n\n(1000, 2)\n\n\nThe data is composed of 2 columns (i.e., random variables). We can visualize the data using a scatter plot.\n\nfig=plt.scatter(data[:,0], data[:,1])"
  },
  {
    "objectID": "exercises/normalizing-flow.html#the-model",
    "href": "exercises/normalizing-flow.html#the-model",
    "title": "Normalizing flow",
    "section": "The model",
    "text": "The model\nThe whole normalizing flow model is composed of multiple coupling layers. So that we avoid code duplication, we will first define our own affine coupling layer, which we will later on reuse when composing our normalizing flow.\n\nAffine coupling layer\nAnd affine coupling layer need to be able to do the following steps:\n\nSplit the input variables (x) into 2 parts - one that stays the same (x1), and one that is being transformed (x2).\nUse x1 to “predict” the shift (mu) and scale (sigma) of the affine transform of x2\nCompute the transformation of x2: x2 = mu + sigma * x2\nConcatenate x1 and the transformed x2\n\n\nclass AffineCoupling(keras.layers.Layer):\n    def __init__(self, swap, n_units, n_layers):\n        \"\"\" This is where we initiate the layer\n        Parameters\n        ----------\n        swap: bool\n            Whether or not to swap x1 and x2\n        n_units: int\n            How many neurons should each layer of our coupling network be\n        n_layers: int\n            How many layers should the coupling network be\n        \"\"\"\n        super(AffineCoupling, self).__init__()\n\n    \n        self.swap = swap\n\n        # Create two networs: one for scale and one for shift \n        self.sigma = keras.Sequential(\n            [keras.layers.Dense(n_units, activation=\"gelu\") for _ in range(n_layers)]\n            )\n        # scale should be always positive, so the ouptut activation is softplus\n        self.sigma.add(keras.layers.Dense(1, activation=\"softplus\"))\n\n        self.mu = keras.Sequential(\n            [keras.layers.Dense(n_units, activation=\"gelu\") for _ in range(n_layers)]\n            )\n        self.mu.add(keras.layers.Dense(1))\n        \n\n    def call(self, x, backward=False):\n        \"\"\" Call the coupling layer\n        \n        1. Split the data in two halfs\n        2. Compute the scale and shift parameters based on one half (x1)\n        3. Scale and shift the other half (x2)\n        4. Concatenate x1 and x2\n\n        Parameters\n        ----------\n        x: Tensor\n            The input data\n        backward: bool\n            Should we do a backward (inverse) transform instead?\n        \"\"\"\n        if self.swap:\n            x2, x1 = keras.ops.split(x, indices_or_sections=2, axis=1)\n        else:\n            x1, x2 = keras.ops.split(x, indices_or_sections=2, axis=1)\n            \n        sigma = self.sigma(x1)\n        mu = self.mu(x1)\n\n        if backward:\n            y2 = x2 * sigma + mu\n            log_det_jac = keras.ops.log(sigma)\n        else:\n            y2 = (x2 - mu) / sigma\n            log_det_jac = -keras.ops.log(sigma)\n\n        if self.swap:\n            y = keras.ops.concatenate([y2, x1], axis=1)\n        else:\n            y = keras.ops.concatenate([x1, y2], axis=1)\n\n        return y, log_det_jac\n\n\n\nNormalizing flow\nThe whole normalizing flow model needs to hold a collection of coupling layers, and alternate between which axis will get transformed. When data are passed in, the network should call the layers sequentially.\nWe will implement\n\n.forward method (data -&gt; base distribution)\n.backward method (base distribution -&gt; data)\n.log_prob method that we will use for training\n.sample method that simply samples from the base distribution and calls the .backward method to produce samples from the data distribution\n\nThe base distribution we chose is Normal, which makes our coupling affine model a Normalizing flow.\n\nclass NormalizingFlow(keras.Model):\n    def __init__(self, n_coupling_layers, n_units, n_layers):\n        \"\"\" Initialize the normalizing flow model\n\n        Parameters\n        ----------\n        n_coupling_layers: int\n            How many coupling layers does the model consist of\n        n_units: int\n            How many neurons should each layer of our coupling layers be\n        n_layers: int\n            How many layers should the coupling network be\n        \"\"\"\n        super(NormalizingFlow, self).__init__()\n        self.coupling_layers = [AffineCoupling(swap=(i % 2 == 0), n_units=n_units, n_layers=n_layers) for i in range(n_coupling_layers)]\n\n    def forward(self, x):\n        \"\"\"Run the normalizing flow in forward direction (data -&gt; base)\n        \"\"\"\n        log_det_jac = keras.ops.zeros(x[...,:1].shape)\n\n        z = x\n        for layer in self.coupling_layers:\n            z, ldj = layer(z)\n            log_det_jac = log_det_jac + ldj\n\n        return z, log_det_jac\n\n    def backward(self, z):\n        \"\"\"Run the normalizing flow in the backward direction (base -&gt; data)\n        \"\"\"\n        log_det_jac = keras.ops.zeros(z[...,:1].shape)\n\n        x = z\n        for layer in reversed(self.coupling_layers):\n            x, ldj = layer(x, backward=True)\n            log_det_jac = log_det_jac + ldj\n        \n        return x, log_det_jac\n\n    def log_prob(self, x):\n        \"\"\"Calculate the log probability of the data\"\"\"\n        z, log_det_jac = self.forward(x)\n        log_prob = self.log_prob_base(z) + log_det_jac\n\n        return log_prob\n\n    def log_prob_base(self, z):\n        \"\"\"Helper method: Calculate the (unnormalized) density of a bivariate normal base distribution\"\"\"\n        kernel = -0.5 * keras.ops.sum(z ** 2, axis=-1)\n        \n        return kernel\n\n    def sample(self, n_samples):\n        \"\"\"Sample from the data distribution\"\"\"\n        z = keras.random.normal((n_samples, 2))\n        x, _ = self.backward(z)\n\n        return x\n\n\nOne we defined our model classes, we can instantiate a new normalizing flow object.\n\n#flow = NormalizingFlow(n_coupling_layers=10, n_units=16, n_layers=4)\nflow = NormalizingFlow(n_coupling_layers=8, n_units=16, n_layers=4)\n\nFor example, you can use the object to forward transform our data samples and plot the results. Because the networks were not trained yet, the results will not be sensible.\n\nz, _ = flow.forward(data)\nfig=plt.scatter(z[:,0], z[:,1])"
  },
  {
    "objectID": "exercises/normalizing-flow.html#training",
    "href": "exercises/normalizing-flow.html#training",
    "title": "Normalizing flow",
    "section": "Training",
    "text": "Training\nWe will use manual training loop for training the normalizing flow model. This should make you see a little bit how the networks are trained.\nTo do this, we will need to define our training schedule, our training data, and, of course, run our training loop.\nFirst, we will need to define our optimizer. Here we will use Adam and use a CosineDecay learning rate schedule to smoothen the training process a little.\nWe will train for a number of epochs. In each epoch, we loop over the entire dataset in batches. For example, if we have 1_000 data samples and we make batches of size 50 samples, we will make 15 steps per epoch. We repeat this for each epoch which will determine the total number of steps. This calculation is important to make sure that the CosineDecay schedule is setup correctly.\n\nepochs=100\nbatch_size=50\nschedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.001, decay_steps=epochs * n_samples // batch_size)\noptimizer = keras.optimizers.Adam(schedule, global_clipnorm=1.0)\n\nFor training, we will use the data that we generated earlier, but we will chop it into separate batches.\n\ndataset = tf.data.Dataset.from_tensor_slices(data.astype(\"float64\"))\ndataset = dataset.batch(batch_size)\n\nTo train the model manually, we will need to implement a function that calculates the gradient of the model weights, given the data. Luckily, tensorflow helps us here by providing a tf.GradientTape, which you can think of as an environment which allows you to automatically calculate the gradients of a custom loss function with respect to the trainable weights provided by the model.\nHere, our loss function is the negative log-likelihood (implemented by our normalizing flow model), and we average it over multiple samples from the data.\n\ndef train_step(model, x):\n    with tf.GradientTape() as tape:\n        loss = - model.log_prob(x)\n        loss = tf.reduce_mean(loss)\n    \n    g = tape.gradient(loss, model.trainable_variables)\n    return g, loss   \n\nNow it is time to implement our training loop.\nWe loop over all epochs. Within each epoch, we loop over all our batches of data. For each batch of data, we compute the loss and the gradient. We pass the gradients to the optimizer which updates the network weights. We also save the computed losses and print them so that we can keep track of the progress.\n\nlosses = []\nfor epoch in range(epochs):\n    epoch_loss = 0.0\n    for batch in dataset:\n        g, loss = train_step(flow, batch)\n        optimizer.apply_gradients(zip(g, flow.trainable_variables))\n        epoch_loss += loss.numpy()\n    epoch_loss = epoch_loss / len(dataset)\n    losses.append(epoch_loss)\n    \n    print(\"epoch: \", epoch+1, \"\\tloss: \", epoch_loss)\n\n2025-03-21 15:38:32.394318: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  1   loss:  4.509119760990143\n\n\n2025-03-21 15:38:37.239786: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  2   loss:  0.4614365412387997\nepoch:  3   loss:  0.03589976973598823\n\n\n2025-03-21 15:38:46.868376: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  4   loss:  -0.07153807431459427\nepoch:  5   loss:  -0.15452831350266932\nepoch:  6   loss:  -0.2195332646369934\nepoch:  7   loss:  -0.3066132962703705\n\n\n2025-03-21 15:39:06.164537: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  8   loss:  -0.3086996302008629\nepoch:  9   loss:  -0.14708678657189012\nepoch:  10  loss:  -0.33719309568405154\nepoch:  11  loss:  -0.5016207732260227\nepoch:  12  loss:  -0.5299644388258458\nepoch:  13  loss:  -0.5786493174731732\nepoch:  14  loss:  -0.4788939183577895\nepoch:  15  loss:  -0.6630645548924804\n\n\n2025-03-21 15:39:46.608116: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  16  loss:  -0.3813606560230255\nepoch:  17  loss:  -0.7215842207893729\nepoch:  18  loss:  -0.6046214617788792\nepoch:  19  loss:  -0.7788489066064358\nepoch:  20  loss:  -0.789466593042016\nepoch:  21  loss:  -0.5925373002886772\nepoch:  22  loss:  -0.846959587931633\nepoch:  23  loss:  0.986885204911232\nepoch:  24  loss:  -0.8945280626416207\nepoch:  25  loss:  165269.66411226988\nepoch:  26  loss:  -0.9101028084754944\nepoch:  27  loss:  -0.9852996498346329\nepoch:  28  loss:  -0.8124980151653289\nepoch:  29  loss:  -0.9974936187267304\nepoch:  30  loss:  -0.9628325670957565\nepoch:  31  loss:  -0.9999727696180344\n\n\n2025-03-21 15:41:05.130025: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  32  loss:  -1.0431531459093093\nepoch:  33  loss:  -1.0677111208438874\nepoch:  34  loss:  -0.9242087975144386\nepoch:  35  loss:  -0.8699889570474625\nepoch:  36  loss:  -1.0687092512845993\nepoch:  37  loss:  -1.0548439770936966\nepoch:  38  loss:  -0.8766490086913109\nepoch:  39  loss:  -0.7317251592874527\nepoch:  40  loss:  -1.0792913630604744\nepoch:  41  loss:  -1.140863972902298\nepoch:  42  loss:  -1.1754374355077744\nepoch:  43  loss:  -1.1837623178958894\nepoch:  44  loss:  -1.203491023182869\nepoch:  45  loss:  -1.2166150778532028\nepoch:  46  loss:  -1.22667535841465\nepoch:  47  loss:  -1.2414973974227905\nepoch:  48  loss:  -1.2488927781581878\nepoch:  49  loss:  -1.2652060627937316\nepoch:  50  loss:  -1.2690628826618195\nepoch:  51  loss:  -1.2715873539447784\nepoch:  52  loss:  -1.268251371383667\nepoch:  53  loss:  -1.2901792645454406\nepoch:  54  loss:  -1.291833186149597\nepoch:  55  loss:  -1.2950453579425811\nepoch:  56  loss:  -1.301222288608551\nepoch:  57  loss:  -1.3077153325080872\nepoch:  58  loss:  -1.3093678325414657\nepoch:  59  loss:  -1.3141041189432143\nepoch:  60  loss:  -1.3188152104616164\nepoch:  61  loss:  -1.32499398291111\nepoch:  62  loss:  -1.330186489224434\nepoch:  63  loss:  -1.3347516715526582\n\n\n2025-03-21 15:43:39.859420: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\nepoch:  64  loss:  -1.3384576618671418\nepoch:  65  loss:  -1.3418648838996887\nepoch:  66  loss:  -1.3449950575828553\nepoch:  67  loss:  -1.347951352596283\nepoch:  68  loss:  -1.3507327556610107\nepoch:  69  loss:  -1.3533526301383971\nepoch:  70  loss:  -1.3557960271835328\nepoch:  71  loss:  -1.3580805480480194\nepoch:  72  loss:  -1.3602263271808623\nepoch:  73  loss:  -1.3622412204742431\nepoch:  74  loss:  -1.3641252756118774\nepoch:  75  loss:  -1.3658817768096925\nepoch:  76  loss:  -1.3675154507160188\nepoch:  77  loss:  -1.3690306961536407\nepoch:  78  loss:  -1.370433324575424\nepoch:  79  loss:  -1.371729701757431\nepoch:  80  loss:  -1.372925877571106\nepoch:  81  loss:  -1.3740281283855438\nepoch:  82  loss:  -1.3750418305397034\nepoch:  83  loss:  -1.3759720921516418\nepoch:  84  loss:  -1.376823902130127\nepoch:  85  loss:  -1.3776013851165771\nepoch:  86  loss:  -1.3783084511756898\nepoch:  87  loss:  -1.378948837518692\nepoch:  88  loss:  -1.3795257031917572\nepoch:  89  loss:  -1.3800430119037628\nepoch:  90  loss:  -1.3805034518241883\nepoch:  91  loss:  -1.380909937620163\nepoch:  92  loss:  -1.3812653243541717\nepoch:  93  loss:  -1.3815723538398743\nepoch:  94  loss:  -1.3818340957164765\nepoch:  95  loss:  -1.3820523381233216\nepoch:  96  loss:  -1.3822305500507355\nepoch:  97  loss:  -1.382369577884674\nepoch:  98  loss:  -1.3824726343154907\nepoch:  99  loss:  -1.3825409412384033\nepoch:  100     loss:  -1.3825759172439576\n\n\nThe losses should decrease over epochs and slowly converge to some minimum. To see how that better, we can plot the losses.\n\nfig=plt.plot(losses)\n\n\n\n\n\n\n\n\nNow, if we apply the network to the data, the transformed variables should look much more like sampled from a bivariate normal distribution.\n\nz, _ = flow.forward(data)\nfig=plt.scatter(z[:,0], z[:,1])\n\n\n\n\n\n\n\n\nAnd conversely we can sample a new data set from the approximate moons distribution using the trained model.\n\ny = flow.sample(n_samples)\nfig = plt.scatter(y[:,0], y[:,1])"
  },
  {
    "objectID": "exercises/flow-matching-datasaurus.html",
    "href": "exercises/flow-matching-datasaurus.html",
    "title": "Flow matching",
    "section": "",
    "text": "In this notebook, we will create our own flow matching network, and train it to reproduce the “datasaurus” distribution.\nWe will use the simplest form of a flow matching.\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport tensorflow as tf\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "exercises/flow-matching-datasaurus.html#the-data",
    "href": "exercises/flow-matching-datasaurus.html#the-data",
    "title": "Flow matching",
    "section": "The data",
    "text": "The data\nThe data set stored in the datasaurus.csv file can be downloaded from the website of the seminar. Download the file in wherever you run this notebook.\nWe read the notebook into a numpy array and also rescale the data.\n\ndata = np.genfromtxt(\"datasaurus.csv\", delimiter=\",\", skip_header=1)\ndata = data/10 - 5\n\nf=plt.scatter(data[:,0], data[:,1], s=5, alpha=0.5)\nf=plt.xlim(-5, 5)\nf=plt.xlim(-5, 5)"
  },
  {
    "objectID": "exercises/flow-matching-datasaurus.html#the-model",
    "href": "exercises/flow-matching-datasaurus.html#the-model",
    "title": "Flow matching",
    "section": "The model",
    "text": "The model\nThe flow matching model is composed of a single MLP network that will take in the samples \\(x_t \\in \\mathbb{R}^2\\) concatenated with the time variable \\(t \\in [0, 1]\\), and outputs a velocity vector \\(v_\\theta(x_t, t) \\in \\mathbb{R}^2\\).\nThe samples x_t are computed by linearly interpolating between samples \\(x_0\\) (sampled from the base distribution) and \\(x_1\\) (sampled from the data distribution):\n\\[\nx_t = (1-t) x_0 + t x_1.\n\\]\nFor sampling, we will implement a basic ODE solver. We will approximate the trajectory of a sample from point \\(x_0\\) into point \\(x_1\\) by moving the point along its velocity in a series of small time steps of \\(dt\\). At each time step, we will approximate the “midpoint” velocity, that is, a velocity that we would expect in the middle of the step (at \\(t + dt/2\\)). In each step, we go from point \\(x_t\\) to point \\(x_{t+dt}\\) as follows,\n\\[\n\\begin{aligned}\nv_t & = v_\\theta(x_t, t) \\\\\n\\hat{x}_\\text{midpoint} & = x_t + v_t \\times dt/2 \\\\\n\\hat{v}_\\text{midpoint} & = v_\\theta(\\hat{x}_\\text{midpoint}, t+dt/2) \\\\\nx_{t+dt} & = x_t + \\hat{v}_\\text{midpoint} \\times dt.\n\\end{aligned}\n\\]\nWe will make these steps all the way from \\(x_0\\) to \\(x_1\\), where the intial points are sampled from the base distribution \\(x_0 \\sim \\text{Normal}(0, I)\\).\n\nclass FlowMatching(keras.Model):\n    def __init__(self, n_units, n_layers, dim=2):\n        \"\"\" Initiate the flow matching model object\n\n        Parameters\n        ----------\n        n_units: int\n            Number of units per each layer of the velocity MLP\n        n_layers: int\n            Number of layers of the velocity MLP\n        dim: int\n            Number of output dimensions (by default 2 because the datasaurus lives in 2D)\n        \"\"\"\n        super(FlowMatching, self).__init__()\n        self.dim = dim\n        self.velocity = keras.Sequential(\n            [keras.layers.Dense(n_units, activation=\"elu\") for _ in range(n_layers)]\n            )\n        self.velocity.add(keras.layers.Dense(dim))\n\n    def call(self, inputs):\n        \"\"\" Call the velocity vector\n\n        Parameters\n        ----------\n        inputs: dict\n            x_0: samples from the base distribution\n            x_1: samples from the data distribution\n            t:   samples of the time variable between [0, 1]\n\n\n        Returns the velocity vector\n        \"\"\"\n        x_0, x_1, t = inputs.values()\n        x_t = (1-t)*x_0 + t*x_1\n        x = keras.ops.concatenate([x_t, t], axis=-1)\n        return self.velocity(x)\n\n    def step(self, x, t, dt):\n        \"\"\" Make one step using the midpoint ODE solver\n\n        Parameters\n        ----------\n        x: tensor/array (batch_size, dim)\n            Samples of the variable x_t\n        t: tuple/array (batch_size,)\n            Samples of the time variable between [0, 1]\n        dt: float\n            The size of the time step\n\n        Returns: tensor/array (batch_size, dim)\n            Samples of the variable x_{t+dt}\n        \"\"\"\n\n        t_start = np.zeros_like(x) + t\n        input_start = keras.ops.concatenate([x, t_start], axis=-1)\n        v = self.velocity(input_start)\n        x_mid = x + v * dt / 2\n\n        t_mid = t_start + dt / 2\n        input_mid = keras.ops.concatenate([x_mid, t_mid], axis=-1)\n        v = self.velocity(input_mid)\n        x_end = x + v * dt\n\n        return x_end\n\n    def run(self, x, steps):\n        \"\"\" Run the ODE solver from t=0 to t=1\n\n        Parameters\n        ----------\n        x: tensor/array (batch_size, dim)\n            Samples from the base distribution, x_0\n        steps: int\n            Number of steps to make between t=0 and t=1\n        \n        Returns: tensor/array (batch_size, dim)\n            Samples x_1 ~ p_1\n        \"\"\"\n        time = np.linspace(0, 1, steps+1)\n        output = []\n        output.append(x)\n        for i in range(steps):\n            x = self.step(x, time[i], time[i+1]-time[i])\n            output.append(x)\n        \n        return output\n\n    def sample(self, n_samples, steps):\n        \"\"\" Sample from the learned distribution\n\n        Parameters\n        ----------\n        n_samples: int\n            Number of samples to take\n        steps: int\n            Number of steps to make between t=0 and t=1 in the ODE\n\n        Returns array (batch_size, steps+1, dim)\n            Samples of x_t ~ p_t\n        \"\"\"\n        x_0 = np.random.normal(size=(n_samples, self.dim))\n        x_1 = self.run(x_0, steps)\n        \n        return np.array(x_1).swapaxes(0, 1)\n\nOne we defined our model class, we can instantiate a new flow matching model object.\n\nflow = FlowMatching(n_units=64, n_layers=8)"
  },
  {
    "objectID": "exercises/flow-matching-datasaurus.html#training",
    "href": "exercises/flow-matching-datasaurus.html#training",
    "title": "Flow matching",
    "section": "Training",
    "text": "Training\nFor training we will take a slightly different approach than in the normalizing flow exercise. Here we will make a new dataset object that will inherit from the PyDataset class. This allows us to get random coupling between the base and the data distribution, as well as the random time variable\nWhenever we want to get a batch of samples, we will simply take a random subset of rows from the datasaurus dataset. This will be our samples \\(x_t\\). Samples from the base distribution will be generated by drawing from a bi-variate normal \\(x_0 \\sim \\text{Normal}(0, I)\\). Lastly, the time variable will be drawn from a uniform distribution \\(t \\sim \\text{Uniform}(0, 1)\\).\nFinally, the target velocity is calculated simply as \\(v = x_1 - x_0\\).\n\nclass DataSet(keras.utils.PyDataset):\n    def __init__(self, batch_size, n_batches, data):\n        super().__init__()\n        self.n_batches=n_batches\n        self.batch_size = batch_size\n        self.data = data\n    \n    @property\n    def num_batches(self):\n        return self.n_batches\n\n    def __getitem__(self, index):\n        data = self.data\n        rows = np.random.choice(data.shape[0], size=self.batch_size, replace=True)\n        data = data[rows]\n\n        base = np.random.normal(size=data.shape)\n        \n        t = np.random.uniform(low=0, high=1, size=data.shape[0])\n        t = np.repeat(t[:,np.newaxis], repeats=data.shape[1], axis=1)\n\n        target = data - base\n        return dict(x_0=base, x_1=data, t=t), target\n\nWe configure the dataset such that every time we sample from it, we will draw a batch of 512 samples.\n\nepochs=20\nbatches=1000\nbatch_size=512\n\ndataset=DataSet(batch_size=batch_size, n_batches=epochs*batches, data=data)\n\nNext, we define our learning rate schedule and optimizer. We will use a Cosine Decay and Adam optimizer.\n\nschedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.01, decay_steps=epochs*batches)\noptimizer = keras.optimizers.Adam(schedule, global_clipnorm=1.0)\n\nNow we can compile the model: we supply the optimizer and add a mean square error loss. This loss will be used to regress the velocity network \\(v_\\theta\\) on the target velocities \\(x_1 - x_0\\).\n\nflow.compile(\n    optimizer=optimizer,\n    loss=keras.losses.MeanSquaredError()\n)\n\nBecause we compiled the model together with an optimizer and a loss, and because we set up our data set object such that it can easily be used on our network, we can simply fit our model with the .fit method - no manual gradient calculation, no manual fitting loop.\n\nhistory=flow.fit(x=dataset, epochs=epochs, steps_per_epoch=batches)\n\nEpoch 1/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 5s 4ms/step - loss: 3.6111\nEpoch 2/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 3.3610\nEpoch 3/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 3.3295\nEpoch 4/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 3.3245\nEpoch 5/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.3200\nEpoch 6/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - loss: 3.3108\nEpoch 7/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2899\nEpoch 8/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2719\nEpoch 9/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2796\nEpoch 10/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2862\nEpoch 11/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2628\nEpoch 12/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2722\nEpoch 13/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2579\nEpoch 14/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2366\nEpoch 15/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2256\nEpoch 16/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2149\nEpoch 17/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2062\nEpoch 18/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2026\nEpoch 19/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.1868\nEpoch 20/20\n1000/1000 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - loss: 3.2060\n\n\n\nf=plt.plot(history.history[\"loss\"])\n\n\n\n\n\n\n\n\nNow that we fitted the model, let’s see the samples it generates!\n\nn_samples=5000\nx = flow.sample(n_samples=n_samples, steps=100)\n# -1 gets the samples at the last time step, e.i, t=1\nf=plt.scatter(x[:, -1, 0], x[:, -1, 1], s=10, alpha=0.5)\nf=plt.xlim(-5, 5)\nf=plt.xlim(-5, 5)"
  }
]